{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"datasetVersion","sourceId":14464186,"datasetId":9238653,"databundleVersionId":15285735,"isSourceIdPinned":false}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"hammadjavaid/vehicle-object-detection-dataset-5-classes\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T16:23:14.481449Z","iopub.execute_input":"2026-02-19T16:23:14.482154Z","iopub.status.idle":"2026-02-19T16:23:15.609887Z","shell.execute_reply.started":"2026-02-19T16:23:14.482115Z","shell.execute_reply":"2026-02-19T16:23:15.609115Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/vehicle-object-detection-dataset-5-classes\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\n\ndataset_path = \"/kaggle/input/vehicle-object-detection-dataset-5-classes\"\n\n# Check if the directory exists\nif os.path.exists(dataset_path):\n    print(f\"Contents of '{dataset_path}':\")\n    for item in os.listdir(dataset_path):\n        print(item)\nelse:\n    print(f\"Error: Directory '{dataset_path}' not found.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T16:23:17.280855Z","iopub.execute_input":"2026-02-19T16:23:17.281687Z","iopub.status.idle":"2026-02-19T16:23:17.291632Z","shell.execute_reply.started":"2026-02-19T16:23:17.281653Z","shell.execute_reply":"2026-02-19T16:23:17.291024Z"}},"outputs":[{"name":"stdout","text":"Contents of '/kaggle/input/vehicle-object-detection-dataset-5-classes':\nvehicles\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\n\n# First, let's check what's actually in the dataset path\nprint(f\"Exploring dataset structure in: {dataset_path}\\n\")\n\n# Function to explore directory structure\ndef explore_directory(path, max_depth=5, current_depth=0):\n    if current_depth > max_depth:\n        return\n    \n    try:\n        items = os.listdir(path)\n        indent = \"  \" * current_depth\n        print(f\"{indent}Contents of '{path}':\")\n        \n        for item in items:\n            item_path = os.path.join(path, item)\n            if os.path.isdir(item_path):\n                print(f\"{indent}  ğŸ“ {item}/\")\n                if current_depth < max_depth:\n                    explore_directory(item_path, max_depth, current_depth + 1)\n            else:\n                print(f\"{indent}  ğŸ“„ {item}\")\n    except Exception as e:\n        print(f\"{indent}Error accessing {path}: {e}\")\n\nexplore_directory(dataset_path, max_depth=2)\n\n# Now try to find the correct dataset subdirectory\npossible_paths = [\n    os.path.join(dataset_path, 'dataset'),\n    dataset_path,  # Sometimes the dataset folder IS the root\n]\n\ndataset_sub_path = None\nfor path in possible_paths:\n    if os.path.exists(path):\n        # Check if this path has 'images' and 'labels' folders\n        contents = os.listdir(path)\n        if 'images' in contents and 'labels' in contents:\n            dataset_sub_path = path\n            print(f\"\\nâœ… Found dataset directory: {dataset_sub_path}\")\n            break\n\nif dataset_sub_path is None:\n    # If still not found, search for images and labels folders\n    for root, dirs, files in os.walk(dataset_path):\n        if 'images' in dirs and 'labels' in dirs:\n            dataset_sub_path = root\n            print(f\"\\nâœ… Found dataset directory: {dataset_sub_path}\")\n            break\n\nif dataset_sub_path:\n    print(f\"\\nContents of dataset directory:\")\n    for item in os.listdir(dataset_sub_path):\n        print(f\"  - {item}\")\nelse:\n    print(\"\\nâŒ Could not find dataset directory with 'images' and 'labels' folders\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T16:23:19.776469Z","iopub.execute_input":"2026-02-19T16:23:19.777092Z","iopub.status.idle":"2026-02-19T16:23:19.814999Z","shell.execute_reply.started":"2026-02-19T16:23:19.777063Z","shell.execute_reply":"2026-02-19T16:23:19.814248Z"}},"outputs":[{"name":"stdout","text":"Exploring dataset structure in: /kaggle/input/vehicle-object-detection-dataset-5-classes\n\nContents of '/kaggle/input/vehicle-object-detection-dataset-5-classes':\n  ğŸ“ vehicles/\n  Contents of '/kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles':\n    ğŸ“„ data.yaml\n    ğŸ“ val/\n    Contents of '/kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/val':\n      ğŸ“ labels/\n      ğŸ“ images/\n    ğŸ“ test/\n    Contents of '/kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/test':\n      ğŸ“ labels/\n      ğŸ“ images/\n    ğŸ“ train/\n    Contents of '/kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/train':\n      ğŸ“ labels/\n      ğŸ“ images/\n\nâœ… Found dataset directory: /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/val\n\nContents of dataset directory:\n  - labels\n  - images\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip install ultralytics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T16:23:24.047553Z","iopub.execute_input":"2026-02-19T16:23:24.048186Z","iopub.status.idle":"2026-02-19T16:23:31.355579Z","shell.execute_reply.started":"2026-02-19T16:23:24.048156Z","shell.execute_reply":"2026-02-19T16:23:31.354580Z"}},"outputs":[{"name":"stdout","text":"Collecting ultralytics\n  Downloading ultralytics-8.4.14-py3-none-any.whl.metadata (39 kB)\nRequirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\nRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\nRequirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\nRequirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\nRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.5)\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.15.3)\nRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\nRequirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\nRequirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\nCollecting ultralytics-thop>=2.0.18 (from ultralytics)\n  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\nRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (26.0rc2)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.6.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2026.1.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.3)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\nDownloading ultralytics-8.4.14-py3-none-any.whl (1.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\nInstalling collected packages: ultralytics-thop, ultralytics\nSuccessfully installed ultralytics-8.4.14 ultralytics-thop-2.0.18\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import ultralytics\n\nprint(f\"Ultralytics version: {ultralytics.__version__}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T16:23:31.357426Z","iopub.execute_input":"2026-02-19T16:23:31.357694Z","iopub.status.idle":"2026-02-19T16:23:39.225165Z","shell.execute_reply.started":"2026-02-19T16:23:31.357664Z","shell.execute_reply":"2026-02-19T16:23:39.224529Z"}},"outputs":[{"name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file âœ… \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\nUltralytics version: 8.4.14\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T16:23:39.226022Z","iopub.execute_input":"2026-02-19T16:23:39.226407Z","iopub.status.idle":"2026-02-19T16:23:39.709186Z","shell.execute_reply.started":"2026-02-19T16:23:39.226379Z","shell.execute_reply":"2026-02-19T16:23:39.708409Z"}},"outputs":[{"name":"stdout","text":"Thu Feb 19 16:23:39 2026       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 580.105.08             Driver Version: 580.105.08     CUDA Version: 13.0     |\n+-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   34C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   34C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n\n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import yaml\nfrom pathlib import Path\n\n# Dataset root (read-only)\nDATASET_DIR = Path(\"/kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles\")\n\n# Writable directory\nWORKING_DIR = Path(\"/kaggle/working\")\n\n# ---- Read existing data.yaml ----\noriginal_yaml = DATASET_DIR / \"data.yaml\"\n\nif not original_yaml.exists():\n    raise FileNotFoundError(\"âŒ data.yaml not found in dataset directory\")\n\nwith open(original_yaml, \"r\") as f:\n    original_data = yaml.safe_load(f)\n\n# Extract class info\nclasses = original_data.get(\"names\", [])\nnc = original_data.get(\"nc\", len(classes))\n\nif not classes or nc == 0:\n    raise ValueError(\"âŒ No classes found in original data.yaml\")\n\n# ---- Create new YOLO config ----\nyolo_data_config = {\n    \"path\": str(DATASET_DIR.resolve()),\n    \"train\": \"train/images\",\n    \"val\": \"val/images\",\n    \"test\": \"test/images\",\n    \"nc\": nc,\n    \"names\": classes\n}\n\n# Save new YAML\nyolo_yaml_path = WORKING_DIR / \"data_yolo.yaml\"\nwith open(yolo_yaml_path, \"w\") as f:\n    yaml.dump(yolo_data_config, f, sort_keys=False)\n\n# Print confirmation\nprint(f\"âœ… data_yolo.yaml file saved to: {yolo_yaml_path}\\n\")\nprint(\"Content of data_yolo.yaml:\")\nprint(yolo_yaml_path.read_text())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T16:23:44.367755Z","iopub.execute_input":"2026-02-19T16:23:44.368473Z","iopub.status.idle":"2026-02-19T16:23:44.387716Z","shell.execute_reply.started":"2026-02-19T16:23:44.368428Z","shell.execute_reply":"2026-02-19T16:23:44.386890Z"}},"outputs":[{"name":"stdout","text":"âœ… data_yolo.yaml file saved to: /kaggle/working/data_yolo.yaml\n\nContent of data_yolo.yaml:\npath: /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles\ntrain: train/images\nval: val/images\ntest: test/images\nnc: 5\nnames:\n- bus\n- car\n- pickup\n- truck\n- van\n\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from ultralytics import YOLO\nimport torch\nimport gc\nimport os\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# CONFIG â€” Adjust model size based on your goal\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nMODEL_SIZE = 's'       # Options: 's' (safe for T4), 'm' (best accuracy, needs batch=8)\nEPOCHS     = 50        # Was 15 â€” more epochs = meaningful gain\nIMG_SIZE   = 800       # Was 640 â€” bigger input improves car/bus detection\nBATCH      = 16        # Use 16 for 8s, 8 for 8m\nPROJECT    = '/kaggle/working'\nRUN_NAME   = f'yolov8{MODEL_SIZE}_tuned'\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# GPU Setup\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ntorch.cuda.empty_cache()\ngc.collect()\n\nprint(f\"ğŸš€ CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# Load Model  (8n â†’ 8s or 8m for +2-5% mAP)\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nmodel = YOLO(f'yolov8{MODEL_SIZE}.pt')\nprint(f\"âœ… Loaded YOLOv8{MODEL_SIZE} â€” {sum(p.numel() for p in model.model.parameters()):,} parameters\")\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# Training\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nprint(f\"\\nğŸ‹ï¸ Starting training: {EPOCHS} epochs | imgsz={IMG_SIZE} | batch={BATCH}\\n\")\n\nresults = model.train(\n    data=str(yolo_yaml_path),   # Your existing yaml path variable\n    epochs=EPOCHS,\n    imgsz=IMG_SIZE,\n    batch=BATCH,\n    device=0,\n    cache='disk',\n    workers=2,\n    patience=15,                # Was 5 â€” give model more room to improve\n    save=True,\n    save_period=5,\n    project=PROJECT,\n    name=RUN_NAME,\n    exist_ok=True,\n    pretrained=True,\n    optimizer='AdamW',\n    verbose=True,\n    seed=42,\n    deterministic=False,\n\n    # â”€â”€ Learning Rate â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    lr0=0.001,                  # Lower LR for fine-tuning pretrained weights\n    lrf=0.01,                   # Final LR = lr0 * lrf\n    momentum=0.937,\n    weight_decay=0.0005,\n    warmup_epochs=3.0,\n    warmup_momentum=0.8,\n\n    # â”€â”€ Scheduler â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    cos_lr=True,\n    close_mosaic=15,            # Was 10 â€” disable mosaic in last 15 epochs\n\n    # â”€â”€ Loss Weights â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    box=9.0,                    # Default 7.5; higher = better localization\n    cls=0.5,\n    dfl=1.5,\n\n    # â”€â”€ Speed / Memory â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    amp=True,\n    fraction=1.0,\n    rect=False,\n    single_cls=False,\n    profile=False,\n\n    # â”€â”€ Augmentation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    hsv_h=0.015,\n    hsv_s=0.7,\n    hsv_v=0.4,\n    degrees=5.0,                # Was 0.0 â€” small rotation helps with angled vehicles\n    translate=0.1,\n    scale=0.6,                  # Was 0.5\n    shear=2.0,                  # Was 0.0 â€” helps generalize across viewpoints\n    perspective=0.0001,\n    flipud=0.0,\n    fliplr=0.5,\n    mosaic=1.0,\n    mixup=0.1,                  # Was 0.0 â€” blends images, reduces overfitting\n    copy_paste=0.1,             # Helps with occluded/overlapping vehicles\n)\n\nprint(\"\\nâœ… Training complete!\")\nprint(f\"   Best weights: {PROJECT}/{RUN_NAME}/weights/best.pt\")\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# Cleanup\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ndel model\ntorch.cuda.empty_cache()\ngc.collect()\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# Validation with Test-Time Augmentation (TTA)\n# Free ~1% mAP boost at inference time\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nbest_weights = f'{PROJECT}/{RUN_NAME}/weights/best.pt'\nassert os.path.exists(best_weights), f\"Weights not found: {best_weights}\"\n\nbest_model = YOLO(best_weights)\nprint(f\"\\nğŸ“‚ Loaded best model: {best_weights}\")\n\n# â”€â”€ Standard validation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nprint(\"\\nğŸ” Running standard validation...\")\nval_results = best_model.val(data=str(yolo_yaml_path), imgsz=IMG_SIZE, device=0)\n\nprint(\"\\nğŸ“Š Standard Validation Results:\")\nprint(f\"   mAP50:     {val_results.box.map50:.4f}\")\nprint(f\"   mAP50-95:  {val_results.box.map:.4f}\")\nprint(f\"   Precision: {val_results.box.mp:.4f}\")\nprint(f\"   Recall:    {val_results.box.mr:.4f}\")\n\n# â”€â”€ TTA validation (augment=True) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nprint(\"\\nğŸ” Running TTA validation (augment=True)...\")\ntta_results = best_model.val(data=str(yolo_yaml_path), imgsz=IMG_SIZE, device=0, augment=True)\n\nprint(\"\\nğŸ“Š TTA Validation Results:\")\nprint(f\"   mAP50:     {tta_results.box.map50:.4f}\")\nprint(f\"   mAP50-95:  {tta_results.box.map:.4f}\")\nprint(f\"   Precision: {tta_results.box.mp:.4f}\")\nprint(f\"   Recall:    {tta_results.box.mr:.4f}\")\n\n# â”€â”€ Summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ngain = tta_results.box.map50 - 0.8639   # Delta from your baseline\nprint(f\"\\nğŸ¯ mAP50 improvement over baseline (0.8639): {gain:+.4f}\")\ntarget_hit = \"âœ… TARGET HIT!\" if tta_results.box.map50 >= 0.90 else \"âš ï¸  Not at 90% yet â€” try 8m or more epochs\"\nprint(f\"   {target_hit}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T16:23:50.783619Z","iopub.execute_input":"2026-02-19T16:23:50.784298Z"}},"outputs":[{"name":"stdout","text":"ğŸš€ CUDA available: True\n   GPU: Tesla T4\n   VRAM: 15.6 GB\n\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolov8s.pt to 'yolov8s.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 21.5MB 150.0MB/s 0.1s.1s<0.1s\nâœ… Loaded YOLOv8s â€” 11,166,560 parameters\n\nğŸ‹ï¸ Starting training: 50 epochs | imgsz=800 | batch=16\n\nUltralytics 8.4.14 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 14913MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=9.0, cache=disk, cfg=None, classes=None, close_mosaic=15, cls=0.5, compile=False, conf=None, copy_paste=0.1, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/kaggle/working/data_yolo.yaml, degrees=5.0, deterministic=False, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=50, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=800, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.1, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=yolov8s_tuned, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=15, perspective=0.0001, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/yolov8s_tuned, save_frames=False, save_json=False, save_period=5, save_txt=False, scale=0.6, seed=42, shear=2.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 14.5MB/s 0.1s\nOverriding model.yaml nc=80 with nc=5\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n 22        [15, 18, 21]  1   2117983  ultralytics.nn.modules.head.Detect           [5, 16, None, [128, 256, 512]]\nModel summary: 130 layers, 11,137,535 parameters, 11,137,519 gradients, 28.7 GFLOPs\n\nTransferred 349/355 items from pretrained weights\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26n.pt to 'yolo26n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.3MB 61.7MB/s 0.1s\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.8Â±0.4 ms, read: 16.4Â±22.4 MB/s, size: 146.0 KB)\n\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/train/labels... 26008 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 26008/26008 178.1it/s 2:26<0.1s\nWARNING âš ï¸ \u001b[34m\u001b[1mtrain: \u001b[0mCache directory /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/train is not writable, cache not saved.\nWARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 205, len(boxes) = 56400. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\nWARNING âš ï¸ \u001b[34m\u001b[1mtrain: \u001b[0mSkipping caching images to disk, directory not writable\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.6Â±0.6 ms, read: 20.6Â±15.7 MB/s, size: 397.6 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/val/labels... 7431 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 7431/7431 183.7it/s 40.5s<0.0s\nWARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/val is not writable, cache not saved.\nWARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 37, len(boxes) = 16299. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\nWARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mSkipping caching images to disk, directory not writable\n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\nPlotting labels to /kaggle/working/yolov8s_tuned/labels.jpg... \nImage sizes 800 train, 800 val\nUsing 2 dataloader workers\nLogging results to \u001b[1m/kaggle/working/yolov8s_tuned\u001b[0m\nStarting training for 50 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       1/50      5.63G      1.516      1.468      1.492         48        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 1.8it/s 15:10<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 1.6it/s 2:28<0.3s\n                   all       7431      16299      0.567      0.545      0.548      0.314\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       2/50      5.41G      1.471      1.336      1.476         31        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 1.9it/s 14:14<0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 1.7it/s 2:17<0.3s\n                   all       7431      16299      0.686      0.649      0.715      0.449\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       3/50      5.31G      1.429      1.246      1.446         52        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 1.9it/s 14:12<0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 1.7it/s 2:21<0.3s\n                   all       7431      16299      0.732      0.689       0.75       0.49\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       4/50      5.42G      1.384      1.156      1.411         33        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 1.9it/s 14:17<0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 1.6it/s 2:24<0.3s\n                   all       7431      16299      0.773      0.716      0.791      0.537\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       5/50      5.43G      1.341      1.091      1.383         34        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 1.9it/s 14:31<0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 1.7it/s 2:20<0.3s\n                   all       7431      16299      0.793      0.748       0.82      0.576\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       6/50      5.33G      1.323      1.048      1.368         28        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 1.9it/s 14:17<0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 1.6it/s 2:22<0.3s\n                   all       7431      16299      0.816      0.758      0.834      0.592\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       7/50      5.45G      1.298      1.006      1.352         37        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 1.9it/s 14:13<0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 1.7it/s 2:20<0.3s\n                   all       7431      16299      0.831      0.759      0.839      0.597\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       8/50      5.38G      1.285     0.9853      1.347         52        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 1.8it/s 14:60<0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 1.6it/s 2:27<0.3s\n                   all       7431      16299      0.815      0.764      0.845      0.612\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       9/50      5.37G      1.267     0.9568      1.333         30        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 2.0it/s 13:29<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 1.7it/s 2:14<0.3s\n                   all       7431      16299      0.811      0.768      0.847      0.617\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      10/50      5.46G      1.255     0.9351      1.328         37        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 1.9it/s 13:58<0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 1.7it/s 2:21<0.3s\n                   all       7431      16299      0.838      0.783      0.863      0.635\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      11/50      5.37G      1.249     0.9177      1.319         62        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 1.9it/s 14:38<0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 1.6it/s 2:26<0.3s\n                   all       7431      16299      0.833      0.796       0.87      0.642\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      12/50       5.4G      1.239     0.9065      1.316         20        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 1.8it/s 14:54<0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 1.6it/s 2:26<0.3s\n                   all       7431      16299      0.839      0.798      0.872      0.644\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      13/50      5.38G      1.235     0.8898       1.31         53        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 1.8it/s 14:47<0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 1.6it/s 2:27<0.3s\n                   all       7431      16299      0.848      0.787      0.875      0.649\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      14/50      5.38G      1.218     0.8678      1.299         34        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 1.8it/s 14:48<0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 1.6it/s 2:26<0.3s\n                   all       7431      16299      0.837      0.807      0.878      0.654\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      15/50      5.47G      1.214     0.8585      1.296         29        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 1.9it/s 14:20<0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 1.7it/s 2:19<0.3s\n                   all       7431      16299      0.845      0.804      0.885      0.658\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      16/50      5.37G      1.202     0.8437      1.291         44        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 2.0it/s 13:42<0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 1.7it/s 2:16<0.3s\n                   all       7431      16299      0.846      0.813      0.886      0.667\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      17/50      5.32G      1.197     0.8378      1.286         30        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 2.0it/s 13:47<0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 1.7it/s 2:14<0.3s\n                   all       7431      16299      0.835      0.825      0.887      0.668\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      18/50       5.4G      1.189      0.819      1.277         30        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 2.0it/s 13:26<0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 1.7it/s 2:17<0.3s\n                   all       7431      16299       0.85      0.815      0.891      0.672\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      19/50      5.34G      1.179       0.81      1.272         27        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 2.0it/s 13:37<0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 1.7it/s 2:15<0.3s\n                   all       7431      16299      0.842      0.833      0.896      0.678\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      20/50      5.41G      1.169      0.797      1.267         54        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 1.9it/s 13:55<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 1.7it/s 2:15<0.3s\n                   all       7431      16299      0.841      0.829      0.895      0.678\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      21/50      5.38G      1.168     0.7911      1.264         34        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 2.0it/s 13:26<0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 1.7it/s 2:13<0.3s\n                   all       7431      16299      0.857      0.828      0.897      0.679\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      22/50      5.41G      1.158     0.7815      1.258         42        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 1.9it/s 13:56<0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 1.6it/s 2:29<0.3s\n                   all       7431      16299      0.856      0.827        0.9      0.684\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      23/50      5.41G      1.157      0.772      1.256         39        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 1.8it/s 14:45<0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 1.6it/s 2:24<0.3s\n                   all       7431      16299      0.863      0.822        0.9      0.686\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      24/50      5.33G      1.148     0.7619      1.251         46        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 2.0it/s 13:51<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 1.8it/s 2:09<0.3ss\n                   all       7431      16299      0.856      0.835      0.902      0.688\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      25/50      5.38G      1.137     0.7498      1.246         32        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 1.9it/s 14:05<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 1.7it/s 2:19<0.3s\n                   all       7431      16299      0.863      0.833      0.903      0.691\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      26/50      5.41G      1.137     0.7449      1.248         44        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 1.9it/s 14:20<0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 1.6it/s 2:27<0.3s\n                   all       7431      16299      0.861      0.835      0.904      0.694\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      27/50       5.4G      1.132     0.7317      1.241         42        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 1.8it/s 14:47<0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 34% â”â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€ 80/233 2.2it/s 33.3s<1:08s","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\nimport torch\nimport gc\n\n# Clear GPU memory\ntorch.cuda.empty_cache()\ngc.collect()\n\n# Load a pre-trained YOLOv8n model\nmodel = YOLO('yolov8n.pt')\n\n\n# Optimized training configuration for Kaggle\nprint(\"Initiating model training...\")\nresults = model.train(\n    data=str(yolo_yaml_path),\n    epochs=15,\n    imgsz=640,\n    batch=16,  # Adjust based on GPU memory (try 8 or 32)\n    device=0,  # Use GPU\n    cache='disk',  # Use disk caching instead of RAM (Kaggle has limited RAM)\n    workers=2,  # Reduce workers to save RAM\n    patience=5,  # Early stopping\n    save=True,\n    save_period=5,  # Save checkpoint every 5 epochs\n    project='/kaggle/working',  # Save to Kaggle working directory\n    name='yolov8_training',\n    exist_ok=True,\n    pretrained=True,\n    optimizer='AdamW',  # Often works better than SGD\n    verbose=True,\n    seed=42,\n    deterministic=False,  # Faster training\n    single_cls=False,\n    rect=False,\n    cos_lr=True,  # Cosine learning rate scheduler\n    close_mosaic=10,  # Disable mosaic augmentation in last 10 epochs\n    amp=True,  # Automatic Mixed Precision for faster training\n    fraction=1.0,  # Use full dataset\n    profile=False,  # Disable profiling to save memory\n    # Augmentation parameters\n    hsv_h=0.015,\n    hsv_s=0.7,\n    hsv_v=0.4,\n    degrees=0.0,\n    translate=0.1,\n    scale=0.5,\n    shear=0.0,\n    perspective=0.0,\n    flipud=0.0,\n    fliplr=0.5,\n    mosaic=1.0,\n    mixup=0.0,\n)\n\nprint(\"Model training completed.\")\n\n# Clear memory after training\ndel model\ntorch.cuda.empty_cache()\ngc.collect()\n\n# Load the best model for inference\nbest_model = YOLO('/kaggle/working/yolov8_training/weights/best.pt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T20:44:56.121420Z","iopub.execute_input":"2026-02-02T20:44:56.121740Z","iopub.status.idle":"2026-02-02T23:10:44.118869Z","shell.execute_reply.started":"2026-02-02T20:44:56.121686Z","shell.execute_reply":"2026-02-02T23:10:44.118250Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\nfrom pathlib import Path\n\n# Paths\nWORKING_DIR = Path(\"/kaggle/working\")\nbest_model_path = WORKING_DIR / \"yolov8_training/weights/best.pt\"\n\n# Load the trained model\nprint(f\"ğŸ“‚ Loading model: {best_model_path}\")\nmodel = YOLO(str(best_model_path))\n\n# Validate\nprint(\"\\nğŸ” Validating YOLOv8 model...\")\nmetrics = model.val()\n\n# Display all metrics\nprint(f\"\\nğŸ“Š Validation Results:\")\nprint(f\"   mAP50:     {metrics.box.map50:.4f}\")\nprint(f\"   mAP50-95:  {metrics.box.map:.4f}\")\nprint(f\"   Precision: {metrics.box.mp:.4f}\")\nprint(f\"   Recall:    {metrics.box.mr:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T23:14:05.624794Z","iopub.execute_input":"2026-02-02T23:14:05.625364Z","iopub.status.idle":"2026-02-02T23:15:42.288046Z","shell.execute_reply.started":"2026-02-02T23:14:05.625333Z","shell.execute_reply":"2026-02-02T23:15:42.287064Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import yaml\nfrom pathlib import Path\n\n# Dataset root (read-only)\nDATASET_DIR = Path(\"/kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles\")\n\n# Writable directory\nWORKING_DIR = Path(\"/kaggle/working\")\n\n# ---- Read existing data.yaml ----\noriginal_yaml = DATASET_DIR / \"data.yaml\"\n\nif not original_yaml.exists():\n    raise FileNotFoundError(\"âŒ data.yaml not found in dataset directory\")\n\nwith open(original_yaml, \"r\") as f:\n    original_data = yaml.safe_load(f)\n\n# Extract class info\nclasses = original_data.get(\"names\", [])\nnc = original_data.get(\"nc\", len(classes))\n\nif not classes or nc == 0:\n    raise ValueError(\"âŒ No classes found in original data.yaml\")\n\n# ---- Create new YOLO config ----\nyolo_data_config = {\n    \"path\": str(DATASET_DIR.resolve()),\n    \"train\": \"train/images\",\n    \"val\": \"val/images\",\n    \"test\": \"test/images\",\n    \"nc\": nc,\n    \"names\": classes\n}\n\n# Save new YAML\nyolo_yaml_path = WORKING_DIR / \"data_yolo.yaml\"\nwith open(yolo_yaml_path, \"w\") as f:\n    yaml.dump(yolo_data_config, f, sort_keys=False)\n\n# Print confirmation\nprint(f\"âœ… data_yolo.yaml file saved to: {yolo_yaml_path}\\n\")\nprint(\"Content of data_yolo.yaml:\")\nprint(yolo_yaml_path.read_text())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T23:15:42.305516Z","iopub.execute_input":"2026-02-02T23:15:42.305897Z","iopub.status.idle":"2026-02-02T23:15:42.324350Z","shell.execute_reply.started":"2026-02-02T23:15:42.305857Z","shell.execute_reply":"2026-02-02T23:15:42.323493Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\nimport torch\nimport gc\n\n# Clear GPU memory\ntorch.cuda.empty_cache()\ngc.collect()\n\n# Load a pre-trained YOLOv10n model\nmodel = YOLO('yolov10n.pt')\n\n# Optimized training configuration for Kaggle\nprint(\"Initiating model training...\")\nresults = model.train(\n    data=str(yolo_yaml_path),\n    epochs=15,\n    imgsz=640,\n    batch=16,  # Adjust: 8 (safer), 16 (balanced), 32 (if no OOM)\n    device=0,  # GPU\n    cache='disk',  # Critical for Kaggle: disk cache instead of RAM\n    workers=2,  # Reduce RAM usage\n    patience=5,  # Early stopping\n    save=True,\n    save_period=5,  # Save checkpoint every 5 epochs\n    project='/kaggle/working',  # Kaggle persistent directory\n    name='yolov10_training',\n    exist_ok=True,\n    pretrained=True,\n    optimizer='AdamW',\n    verbose=True,\n    seed=42,\n    deterministic=False,\n    amp=True,  # Automatic Mixed Precision - faster training\n    cos_lr=True,  # Cosine LR scheduler\n    close_mosaic=10,  # Disable mosaic in last 10 epochs\n    profile=False,  # Save memory\n    # Augmentation parameters (augment=True is deprecated, use individual params)\n    hsv_h=0.015,\n    hsv_s=0.7,\n    hsv_v=0.4,\n    degrees=0.0,\n    translate=0.1,\n    scale=0.5,\n    shear=0.0,\n    perspective=0.0,\n    flipud=0.0,\n    fliplr=0.5,\n    mosaic=1.0,\n    mixup=0.0,\n    copy_paste=0.0,\n)\n\nprint(\"Model training completed.\")\n\n# Clear memory\ndel model\ntorch.cuda.empty_cache()\ngc.collect()\n\n# Load best model\nbest_model = YOLO('/kaggle/working/yolov10_training/weights/best.pt')\nprint(f\"Best model loaded from: /kaggle/working/yolov10_training/weights/best.pt\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\nfrom pathlib import Path\n\n# Paths\nWORKING_DIR = Path(\"/kaggle/working\")\nbest_model_path = WORKING_DIR / \"yolov10_training/weights/best.pt\"\n\n# Load the trained model\nprint(f\"ğŸ“‚ Loading model: {best_model_path}\")\nmodel = YOLO(str(best_model_path))\n\n# Validate\nprint(\"\\nğŸ” Validating YOLOv10n model...\")\nmetrics = model.val()\n\n# Display all metrics\nprint(f\"\\nğŸ“Š Validation Results:\")\nprint(f\"   mAP50:     {metrics.box.map50:.4f}\")\nprint(f\"   mAP50-95:  {metrics.box.map:.4f}\")\nprint(f\"   Precision: {metrics.box.mp:.4f}\")\nprint(f\"   Recall:    {metrics.box.mr:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-03T02:07:01.072248Z","iopub.execute_input":"2026-02-03T02:07:01.072549Z","iopub.status.idle":"2026-02-03T02:08:47.761341Z","shell.execute_reply.started":"2026-02-03T02:07:01.072519Z","shell.execute_reply":"2026-02-03T02:08:47.760248Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import yaml\nfrom pathlib import Path\n\n# Dataset root (read-only)\nDATASET_DIR = Path(\"/kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles\")\n# Writable directory\nWORKING_DIR = Path(\"/kaggle/working\")\n\n# ---- Read existing data.yaml ----\noriginal_yaml = DATASET_DIR / \"data.yaml\"\nif not original_yaml.exists():\n    raise FileNotFoundError(\"âŒ data.yaml not found in dataset directory\")\n\nwith open(original_yaml, \"r\") as f:\n    original_data = yaml.safe_load(f)\n\n# Extract class info\nclasses = original_data.get(\"names\", [])\nnc = original_data.get(\"nc\", len(classes))\n\nif not classes or nc == 0:\n    raise ValueError(\"âŒ No classes found in original data.yaml\")\n\n# ---- Create new YOLO config ----\nyolo_data_config = {\n    \"path\": str(DATASET_DIR.resolve()),\n    \"train\": \"train/images\",\n    \"val\": \"val/images\",\n    \"test\": \"test/images\",\n    \"nc\": nc,\n    \"names\": classes\n}\n\n# Save new YAML\nyolo_yaml_path = WORKING_DIR / \"data_yolo.yaml\"\nwith open(yolo_yaml_path, \"w\") as f:\n    yaml.dump(yolo_data_config, f, sort_keys=False)\n\n# Print confirmation\nprint(f\"âœ… data_yolo.yaml file saved to: {yolo_yaml_path}\\n\")\nprint(\"Content of data_yolo.yaml:\")\nprint(yolo_yaml_path.read_text())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-03T07:25:15.201384Z","iopub.execute_input":"2026-02-03T07:25:15.202069Z","iopub.status.idle":"2026-02-03T07:25:15.247224Z","shell.execute_reply.started":"2026-02-03T07:25:15.202035Z","shell.execute_reply":"2026-02-03T07:25:15.246618Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\nimport torch\nimport gc\n\n# Clear GPU memory\ntorch.cuda.empty_cache()\ngc.collect()\n\n# Load a pre-trained YOLOv11n model\nmodel = YOLO('yolo11n.pt')\n\n# Train the model\nprint(\"ğŸš€ Initiating YOLOv11 model training...\")\nresults = model.train(\n    data=str(yolo_yaml_path), \n    epochs=20, \n    imgsz=640, \n    batch=16,  # Adjust: 8 (safer), 16 (balanced), 24-32 (if no OOM)\n    device=0,  # Enable GPU - CRITICAL for Kaggle!\n    cache='disk',  # Use disk cache instead of RAM (Kaggle has limited RAM)\n    workers=2,  # Reduce RAM usage from data loading\n    patience=5,  # Early stopping to save GPU hours\n    save=True,\n    save_period=5,  # Save checkpoint every 5 epochs (safety for timeouts)\n    project='/kaggle/working/yolov11_training',  # Kaggle persistent directory\n    name='vehicle_detection',\n    exist_ok=True,\n    pretrained=True,\n    optimizer='AdamW',  # Often better than SGD\n    verbose=True,\n    seed=42,\n    deterministic=False,  # Faster training\n    amp=True,  # Automatic Mixed Precision - faster on T4/P100\n    cos_lr=True,  # Cosine learning rate scheduler\n    close_mosaic=10,  # Disable mosaic in last 10 epochs for better accuracy\n    profile=False,  # Disable profiling to save memory\n    plots=True,  # Generate training plots\n    # Augmentation parameters (augment=True is deprecated)\n    hsv_h=0.015,  # Hue augmentation\n    hsv_s=0.7,    # Saturation augmentation\n    hsv_v=0.4,    # Value augmentation\n    degrees=0.0,  # Rotation (0-10 for vehicles)\n    translate=0.1,  # Translation\n    scale=0.5,    # Scale augmentation\n    shear=0.0,    # Shear\n    perspective=0.0,  # Perspective\n    flipud=0.0,   # Vertical flip (usually 0 for vehicles)\n    fliplr=0.5,   # Horizontal flip (0.5 for vehicles)\n    mosaic=1.0,   # Mosaic augmentation\n    mixup=0.0,    # Mixup augmentation\n    copy_paste=0.0,  # Copy-paste augmentation\n)\nprint(\"âœ… YOLOv11 model training completed.\")\n\n# Clear memory after training\ndel model\ntorch.cuda.empty_cache()\ngc.collect()\n\n# Load the best model for validation/inference\nprint(\"ğŸ“¦ Loading best trained model...\")\nbest_model = YOLO('/kaggle/working/yolov11_training/vehicle_detection/weights/best.pt')\nprint(f\"âœ… Best model loaded from: /kaggle/working/yolov11_training/vehicle_detection/weights/best.pt\")\n\n# Optional: Validate the model\nprint(\"ğŸ“Š Validating model performance...\")\nmetrics = best_model.val()\nprint(f\"mAP50-95: {metrics.box.map}\")\nprint(f\"mAP50: {metrics.box.map50}\")\nprint(f\"mAP75: {metrics.box.map75}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-03T07:27:09.008809Z","iopub.execute_input":"2026-02-03T07:27:09.009421Z","iopub.status.idle":"2026-02-03T10:50:27.978665Z","shell.execute_reply.started":"2026-02-03T07:27:09.009388Z","shell.execute_reply":"2026-02-03T10:50:27.977826Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\nfrom pathlib import Path\n\n# Paths\nWORKING_DIR = Path(\"/kaggle/working\")\nbest_model_path = WORKING_DIR / \"yolov11_training/vehicle_detection/weights/best.pt\"\n\n# Load the trained model\nprint(f\"ğŸ“‚ Loading model: {best_model_path}\")\nmodel = YOLO(str(best_model_path))\n\n# Validate\nprint(\"\\nğŸ” Validating YOLOv11 model...\")  # Fixed comment\nmetrics = model.val()\n\n# Display all metrics\nprint(f\"\\nğŸ“Š Validation Results:\")\nprint(f\"   mAP50:     {metrics.box.map50:.4f}\")\nprint(f\"   mAP50-95:  {metrics.box.map:.4f}\")\nprint(f\"   Precision: {metrics.box.mp:.4f}\")\nprint(f\"   Recall:    {metrics.box.mr:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-03T10:50:27.980472Z","iopub.execute_input":"2026-02-03T10:50:27.980964Z","iopub.status.idle":"2026-02-03T10:52:10.194501Z","shell.execute_reply.started":"2026-02-03T10:50:27.980929Z","shell.execute_reply":"2026-02-03T10:52:10.193677Z"}},"outputs":[],"execution_count":null}]}