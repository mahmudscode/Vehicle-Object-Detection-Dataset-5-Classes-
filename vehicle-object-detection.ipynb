{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14464186,"sourceType":"datasetVersion","datasetId":9238653,"isSourceIdPinned":false}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"hammadjavaid/vehicle-object-detection-dataset-5-classes\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T20:44:45.655902Z","iopub.execute_input":"2026-02-02T20:44:45.656226Z","iopub.status.idle":"2026-02-02T20:44:46.391830Z","shell.execute_reply.started":"2026-02-02T20:44:45.656199Z","shell.execute_reply":"2026-02-02T20:44:46.391228Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/vehicle-object-detection-dataset-5-classes\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\n\ndataset_path = \"/kaggle/input/vehicle-object-detection-dataset-5-classes\"\n\n# Check if the directory exists\nif os.path.exists(dataset_path):\n    print(f\"Contents of '{dataset_path}':\")\n    for item in os.listdir(dataset_path):\n        print(item)\nelse:\n    print(f\"Error: Directory '{dataset_path}' not found.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T20:44:46.393011Z","iopub.execute_input":"2026-02-02T20:44:46.393294Z","iopub.status.idle":"2026-02-02T20:44:46.400681Z","shell.execute_reply.started":"2026-02-02T20:44:46.393270Z","shell.execute_reply":"2026-02-02T20:44:46.399861Z"}},"outputs":[{"name":"stdout","text":"Contents of '/kaggle/input/vehicle-object-detection-dataset-5-classes':\nvehicles\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\n\n# First, let's check what's actually in the dataset path\nprint(f\"Exploring dataset structure in: {dataset_path}\\n\")\n\n# Function to explore directory structure\ndef explore_directory(path, max_depth=5, current_depth=0):\n    if current_depth > max_depth:\n        return\n    \n    try:\n        items = os.listdir(path)\n        indent = \"  \" * current_depth\n        print(f\"{indent}Contents of '{path}':\")\n        \n        for item in items:\n            item_path = os.path.join(path, item)\n            if os.path.isdir(item_path):\n                print(f\"{indent}  üìÅ {item}/\")\n                if current_depth < max_depth:\n                    explore_directory(item_path, max_depth, current_depth + 1)\n            else:\n                print(f\"{indent}  üìÑ {item}\")\n    except Exception as e:\n        print(f\"{indent}Error accessing {path}: {e}\")\n\nexplore_directory(dataset_path, max_depth=2)\n\n# Now try to find the correct dataset subdirectory\npossible_paths = [\n    os.path.join(dataset_path, 'dataset'),\n    dataset_path,  # Sometimes the dataset folder IS the root\n]\n\ndataset_sub_path = None\nfor path in possible_paths:\n    if os.path.exists(path):\n        # Check if this path has 'images' and 'labels' folders\n        contents = os.listdir(path)\n        if 'images' in contents and 'labels' in contents:\n            dataset_sub_path = path\n            print(f\"\\n‚úÖ Found dataset directory: {dataset_sub_path}\")\n            break\n\nif dataset_sub_path is None:\n    # If still not found, search for images and labels folders\n    for root, dirs, files in os.walk(dataset_path):\n        if 'images' in dirs and 'labels' in dirs:\n            dataset_sub_path = root\n            print(f\"\\n‚úÖ Found dataset directory: {dataset_sub_path}\")\n            break\n\nif dataset_sub_path:\n    print(f\"\\nContents of dataset directory:\")\n    for item in os.listdir(dataset_sub_path):\n        print(f\"  - {item}\")\nelse:\n    print(\"\\n‚ùå Could not find dataset directory with 'images' and 'labels' folders\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T20:44:46.401530Z","iopub.execute_input":"2026-02-02T20:44:46.401789Z","iopub.status.idle":"2026-02-02T20:44:46.427495Z","shell.execute_reply.started":"2026-02-02T20:44:46.401767Z","shell.execute_reply":"2026-02-02T20:44:46.426874Z"}},"outputs":[{"name":"stdout","text":"Exploring dataset structure in: /kaggle/input/vehicle-object-detection-dataset-5-classes\n\nContents of '/kaggle/input/vehicle-object-detection-dataset-5-classes':\n  üìÅ vehicles/\n  Contents of '/kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles':\n    üìÑ data.yaml\n    üìÅ val/\n    Contents of '/kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/val':\n      üìÅ labels/\n      üìÅ images/\n    üìÅ test/\n    Contents of '/kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/test':\n      üìÅ labels/\n      üìÅ images/\n    üìÅ train/\n    Contents of '/kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/train':\n      üìÅ labels/\n      üìÅ images/\n\n‚úÖ Found dataset directory: /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/val\n\nContents of dataset directory:\n  - labels\n  - images\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip install ultralytics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-03T07:26:50.481726Z","iopub.execute_input":"2026-02-03T07:26:50.482107Z","iopub.status.idle":"2026-02-03T07:26:57.270866Z","shell.execute_reply.started":"2026-02-03T07:26:50.482082Z","shell.execute_reply":"2026-02-03T07:26:57.270121Z"}},"outputs":[{"name":"stdout","text":"Collecting ultralytics\n  Downloading ultralytics-8.4.10-py3-none-any.whl.metadata (38 kB)\nRequirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\nRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\nRequirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\nRequirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\nRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.5)\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.15.3)\nRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\nRequirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\nRequirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\nCollecting ultralytics-thop>=2.0.18 (from ultralytics)\n  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\nRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (26.0rc2)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.6.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2026.1.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.3)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\nDownloading ultralytics-8.4.10-py3-none-any.whl (1.2 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\nInstalling collected packages: ultralytics-thop, ultralytics\nSuccessfully installed ultralytics-8.4.10 ultralytics-thop-2.0.18\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import ultralytics\n\nprint(f\"Ultralytics version: {ultralytics.__version__}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T20:44:51.771397Z","iopub.execute_input":"2026-02-02T20:44:51.771655Z","iopub.status.idle":"2026-02-02T20:44:55.623972Z","shell.execute_reply.started":"2026-02-02T20:44:51.771627Z","shell.execute_reply":"2026-02-02T20:44:55.623386Z"}},"outputs":[{"name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file ‚úÖ \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\nUltralytics version: 8.4.10\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T20:44:55.624850Z","iopub.execute_input":"2026-02-02T20:44:55.625280Z","iopub.status.idle":"2026-02-02T20:44:56.105024Z","shell.execute_reply.started":"2026-02-02T20:44:55.625233Z","shell.execute_reply":"2026-02-02T20:44:56.104271Z"}},"outputs":[{"name":"stdout","text":"Mon Feb  2 20:44:55 2026       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 580.105.08             Driver Version: 580.105.08     CUDA Version: 13.0     |\n+-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   38C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   39C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n\n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import yaml\nfrom pathlib import Path\n\n# Dataset root (read-only)\nDATASET_DIR = Path(\"/kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles\")\n\n# Writable directory\nWORKING_DIR = Path(\"/kaggle/working\")\n\n# ---- Read existing data.yaml ----\noriginal_yaml = DATASET_DIR / \"data.yaml\"\n\nif not original_yaml.exists():\n    raise FileNotFoundError(\"‚ùå data.yaml not found in dataset directory\")\n\nwith open(original_yaml, \"r\") as f:\n    original_data = yaml.safe_load(f)\n\n# Extract class info\nclasses = original_data.get(\"names\", [])\nnc = original_data.get(\"nc\", len(classes))\n\nif not classes or nc == 0:\n    raise ValueError(\"‚ùå No classes found in original data.yaml\")\n\n# ---- Create new YOLO config ----\nyolo_data_config = {\n    \"path\": str(DATASET_DIR.resolve()),\n    \"train\": \"train/images\",\n    \"val\": \"val/images\",\n    \"test\": \"test/images\",\n    \"nc\": nc,\n    \"names\": classes\n}\n\n# Save new YAML\nyolo_yaml_path = WORKING_DIR / \"data_yolo.yaml\"\nwith open(yolo_yaml_path, \"w\") as f:\n    yaml.dump(yolo_data_config, f, sort_keys=False)\n\n# Print confirmation\nprint(f\"‚úÖ data_yolo.yaml file saved to: {yolo_yaml_path}\\n\")\nprint(\"Content of data_yolo.yaml:\")\nprint(yolo_yaml_path.read_text())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T20:44:56.106185Z","iopub.execute_input":"2026-02-02T20:44:56.106528Z","iopub.status.idle":"2026-02-02T20:44:56.120341Z","shell.execute_reply.started":"2026-02-02T20:44:56.106494Z","shell.execute_reply":"2026-02-02T20:44:56.119778Z"}},"outputs":[{"name":"stdout","text":"‚úÖ data_yolo.yaml file saved to: /kaggle/working/data_yolo.yaml\n\nContent of data_yolo.yaml:\npath: /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles\ntrain: train/images\nval: val/images\ntest: test/images\nnc: 5\nnames:\n- bus\n- car\n- pickup\n- truck\n- van\n\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from ultralytics import YOLO\nimport torch\nimport gc\n\n# Clear GPU memory\ntorch.cuda.empty_cache()\ngc.collect()\n\n# Load a pre-trained YOLOv8n model\nmodel = YOLO('yolov8n.pt')\n\n\n# Optimized training configuration for Kaggle\nprint(\"Initiating model training...\")\nresults = model.train(\n    data=str(yolo_yaml_path),\n    epochs=15,\n    imgsz=640,\n    batch=16,  # Adjust based on GPU memory (try 8 or 32)\n    device=0,  # Use GPU\n    cache='disk',  # Use disk caching instead of RAM (Kaggle has limited RAM)\n    workers=2,  # Reduce workers to save RAM\n    patience=5,  # Early stopping\n    save=True,\n    save_period=5,  # Save checkpoint every 5 epochs\n    project='/kaggle/working',  # Save to Kaggle working directory\n    name='yolov8_training',\n    exist_ok=True,\n    pretrained=True,\n    optimizer='AdamW',  # Often works better than SGD\n    verbose=True,\n    seed=42,\n    deterministic=False,  # Faster training\n    single_cls=False,\n    rect=False,\n    cos_lr=True,  # Cosine learning rate scheduler\n    close_mosaic=10,  # Disable mosaic augmentation in last 10 epochs\n    amp=True,  # Automatic Mixed Precision for faster training\n    fraction=1.0,  # Use full dataset\n    profile=False,  # Disable profiling to save memory\n    # Augmentation parameters\n    hsv_h=0.015,\n    hsv_s=0.7,\n    hsv_v=0.4,\n    degrees=0.0,\n    translate=0.1,\n    scale=0.5,\n    shear=0.0,\n    perspective=0.0,\n    flipud=0.0,\n    fliplr=0.5,\n    mosaic=1.0,\n    mixup=0.0,\n)\n\nprint(\"Model training completed.\")\n\n# Clear memory after training\ndel model\ntorch.cuda.empty_cache()\ngc.collect()\n\n# Load the best model for inference\nbest_model = YOLO('/kaggle/working/yolov8_training/weights/best.pt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T20:44:56.121420Z","iopub.execute_input":"2026-02-02T20:44:56.121740Z","iopub.status.idle":"2026-02-02T23:10:44.118869Z","shell.execute_reply.started":"2026-02-02T20:44:56.121686Z","shell.execute_reply":"2026-02-02T23:10:44.118250Z"}},"outputs":[{"name":"stdout","text":"\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolov8n.pt to 'yolov8n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6.2MB 77.9MB/s 0.1s\nInitiating model training...\nUltralytics 8.4.10 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 14913MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=disk, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/kaggle/working/data_yolo.yaml, degrees=0.0, deterministic=False, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=15, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=yolov8_training, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=5, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/yolov8_training, save_frames=False, save_json=False, save_period=5, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 755.1KB 16.4MB/s 0.0s\nOverriding model.yaml nc=80 with nc=5\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1    752287  ultralytics.nn.modules.head.Detect           [5, 16, None, [64, 128, 256]] \nModel summary: 130 layers, 3,011,823 parameters, 3,011,807 gradients, 8.2 GFLOPs\n\nTransferred 319/355 items from pretrained weights\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26n.pt to 'yolo26n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.3MB 43.0MB/s 0.1s.1s<0.1s\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.2¬±0.2 ms, read: 24.6¬±31.1 MB/s, size: 146.0 KB)\n\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/train/labels... 26008 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 26008/26008 347.7it/s 1:15<0.0ss\nWARNING ‚ö†Ô∏è \u001b[34m\u001b[1mtrain: \u001b[0mCache directory /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/train is not writable, cache not saved.\nWARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 205, len(boxes) = 56400. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\nWARNING ‚ö†Ô∏è \u001b[34m\u001b[1mtrain: \u001b[0mSkipping caching images to disk, directory not writable\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.5¬±0.8 ms, read: 50.1¬±56.5 MB/s, size: 397.6 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/val/labels... 7431 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 7431/7431 317.3it/s 23.4s<0.0s\nWARNING ‚ö†Ô∏è \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/val is not writable, cache not saved.\nWARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 37, len(boxes) = 16299. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\nWARNING ‚ö†Ô∏è \u001b[34m\u001b[1mval: \u001b[0mSkipping caching images to disk, directory not writable\nPlotting labels to /kaggle/working/yolov8_training/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.01, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1m/kaggle/working/yolov8_training\u001b[0m\nStarting training for 15 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       1/15      2.06G      1.304      1.724      1.446         45        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.1it/s 8:41<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 2.7it/s 1:25<0.2ss\n                   all       7431      16299      0.229      0.262      0.222      0.121\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       2/15      3.37G      1.248      1.485      1.408         17        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.3it/s 8:08<0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 2.9it/s 1:21<0.2ss\n                   all       7431      16299      0.505      0.485       0.48        0.3\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       3/15      3.38G      1.182      1.338      1.357         35        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.3it/s 8:12<0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 2.9it/s 1:20<0.2ss\n                   all       7431      16299      0.649      0.553      0.606      0.405\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       4/15       3.4G      1.133      1.222      1.322         30        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.4it/s 8:04<0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 2.9it/s 1:20<0.2ss\n                   all       7431      16299      0.719      0.632       0.71      0.489\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       5/15      3.41G      1.098       1.14      1.297         27        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.3it/s 8:10<0.5s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 2.9it/s 1:19<0.2ss\n                   all       7431      16299      0.727      0.667      0.742      0.523\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       6/15      3.43G      1.103       1.01      1.324         22        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.4it/s 7:56<0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 3.0it/s 1:19<0.2ss\n                   all       7431      16299      0.764      0.667      0.756      0.535\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       7/15      3.45G      1.075     0.9406      1.298         11        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.5it/s 7:47<0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 3.0it/s 1:17<0.2ss\n                   all       7431      16299      0.792        0.7      0.793      0.578\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       8/15      3.47G       1.05      0.886      1.274          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.4it/s 7:53<0.5s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 2.9it/s 1:20<0.2ss\n                   all       7431      16299      0.799      0.732      0.813      0.604\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       9/15      3.48G      1.026      0.833      1.257         21        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.4it/s 7:53<0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 2.9it/s 1:19<0.2ss\n                   all       7431      16299      0.803      0.736      0.822      0.614\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      10/15       3.5G      1.004     0.7888      1.233         25        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.5it/s 7:51<0.5s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 3.0it/s 1:18<0.2ss\n                   all       7431      16299      0.834       0.75      0.838       0.63\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      11/15      3.51G     0.9835     0.7546      1.221         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.5it/s 7:49<0.5s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 3.0it/s 1:18<0.2ss\n                   all       7431      16299      0.836      0.765      0.848      0.643\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      12/15      3.54G     0.9692     0.7241      1.206         11        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.4it/s 7:54<0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 2.9it/s 1:19<0.2ss\n                   all       7431      16299      0.839      0.771      0.853       0.65\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      13/15      3.55G     0.9521     0.6947      1.194         15        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.2it/s 8:24<0.5s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 2.6it/s 1:28<0.2ss\n                   all       7431      16299      0.848      0.773      0.859      0.655\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      14/15      3.57G     0.9458     0.6726      1.188         35        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.2it/s 8:28<0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 2.9it/s 1:19<0.2ss\n                   all       7431      16299      0.854      0.774      0.861      0.658\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      15/15      3.58G     0.9333      0.659      1.178         19        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.4it/s 7:59<0.5s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 2.9it/s 1:20<0.2ss\n                   all       7431      16299      0.857      0.773      0.864      0.662\n\n15 epochs completed in 2.357 hours.\nOptimizer stripped from /kaggle/working/yolov8_training/weights/last.pt, 6.2MB\nOptimizer stripped from /kaggle/working/yolov8_training/weights/best.pt, 6.2MB\n\nValidating /kaggle/working/yolov8_training/weights/best.pt...\nUltralytics 8.4.10 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 14913MiB)\nModel summary (fused): 73 layers, 3,006,623 parameters, 0 gradients, 8.1 GFLOPs\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 2.9it/s 1:21<0.2ss\n                   all       7431      16299      0.857      0.773      0.864      0.663\n                   bus       1967       3248      0.863      0.751      0.858      0.599\n                   car       3695       8177      0.862      0.748      0.851      0.565\n                pickup       2048       2383      0.868      0.801      0.875      0.661\n                 truck       1586       2017      0.881      0.781      0.884      0.712\n                   van        455        474      0.812      0.785       0.85      0.776\nSpeed: 0.1ms preprocess, 1.7ms inference, 0.0ms loss, 1.1ms postprocess per image\nResults saved to \u001b[1m/kaggle/working/yolov8_training\u001b[0m\nModel training completed.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from ultralytics import YOLO\nfrom pathlib import Path\n\n# Paths\nWORKING_DIR = Path(\"/kaggle/working\")\nbest_model_path = WORKING_DIR / \"yolov8_training/weights/best.pt\"\n\n# Load the trained model\nprint(f\"üìÇ Loading model: {best_model_path}\")\nmodel = YOLO(str(best_model_path))\n\n# Validate\nprint(\"\\nüîç Validating YOLOv8 model...\")\nmetrics = model.val()\n\n# Display all metrics\nprint(f\"\\nüìä Validation Results:\")\nprint(f\"   mAP50:     {metrics.box.map50:.4f}\")\nprint(f\"   mAP50-95:  {metrics.box.map:.4f}\")\nprint(f\"   Precision: {metrics.box.mp:.4f}\")\nprint(f\"   Recall:    {metrics.box.mr:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T23:14:05.624794Z","iopub.execute_input":"2026-02-02T23:14:05.625364Z","iopub.status.idle":"2026-02-02T23:15:42.288046Z","shell.execute_reply.started":"2026-02-02T23:14:05.625333Z","shell.execute_reply":"2026-02-02T23:15:42.287064Z"}},"outputs":[{"name":"stdout","text":"üìÇ Loading model: /kaggle/working/yolov8_training/weights/best.pt\n\nüîç Validating YOLOv8 model...\nUltralytics 8.4.10 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 14913MiB)\nModel summary (fused): 73 layers, 3,006,623 parameters, 0 gradients, 8.1 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 174.9¬±175.7 MB/s, size: 90.5 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/val/labels... 7431 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 7431/7431 715.6it/s 10.4s0.1s\nWARNING ‚ö†Ô∏è \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/val is not writable, cache not saved.\nWARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 37, len(boxes) = 16299. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 465/465 5.8it/s 1:21<0.1sss\n                   all       7431      16299      0.859      0.773      0.864      0.662\n                   bus       1967       3248      0.864       0.75      0.858      0.599\n                   car       3695       8177      0.863      0.748      0.851      0.565\n                pickup       2048       2383      0.867      0.802      0.875      0.661\n                 truck       1586       2017      0.881      0.781      0.884      0.711\n                   van        455        474      0.817      0.787       0.85      0.775\nSpeed: 0.7ms preprocess, 2.7ms inference, 0.0ms loss, 1.0ms postprocess per image\nResults saved to \u001b[1m/kaggle/working/runs/detect/val\u001b[0m\n\nüìä Validation Results:\n   mAP50:     0.8639\n   mAP50-95:  0.6624\n   Precision: 0.8585\n   Recall:    0.7735\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import yaml\nfrom pathlib import Path\n\n# Dataset root (read-only)\nDATASET_DIR = Path(\"/kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles\")\n\n# Writable directory\nWORKING_DIR = Path(\"/kaggle/working\")\n\n# ---- Read existing data.yaml ----\noriginal_yaml = DATASET_DIR / \"data.yaml\"\n\nif not original_yaml.exists():\n    raise FileNotFoundError(\"‚ùå data.yaml not found in dataset directory\")\n\nwith open(original_yaml, \"r\") as f:\n    original_data = yaml.safe_load(f)\n\n# Extract class info\nclasses = original_data.get(\"names\", [])\nnc = original_data.get(\"nc\", len(classes))\n\nif not classes or nc == 0:\n    raise ValueError(\"‚ùå No classes found in original data.yaml\")\n\n# ---- Create new YOLO config ----\nyolo_data_config = {\n    \"path\": str(DATASET_DIR.resolve()),\n    \"train\": \"train/images\",\n    \"val\": \"val/images\",\n    \"test\": \"test/images\",\n    \"nc\": nc,\n    \"names\": classes\n}\n\n# Save new YAML\nyolo_yaml_path = WORKING_DIR / \"data_yolo.yaml\"\nwith open(yolo_yaml_path, \"w\") as f:\n    yaml.dump(yolo_data_config, f, sort_keys=False)\n\n# Print confirmation\nprint(f\"‚úÖ data_yolo.yaml file saved to: {yolo_yaml_path}\\n\")\nprint(\"Content of data_yolo.yaml:\")\nprint(yolo_yaml_path.read_text())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T23:15:42.305516Z","iopub.execute_input":"2026-02-02T23:15:42.305897Z","iopub.status.idle":"2026-02-02T23:15:42.324350Z","shell.execute_reply.started":"2026-02-02T23:15:42.305857Z","shell.execute_reply":"2026-02-02T23:15:42.323493Z"}},"outputs":[{"name":"stdout","text":"‚úÖ data_yolo.yaml file saved to: /kaggle/working/data_yolo.yaml\n\nContent of data_yolo.yaml:\npath: /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles\ntrain: train/images\nval: val/images\ntest: test/images\nnc: 5\nnames:\n- bus\n- car\n- pickup\n- truck\n- van\n\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"from ultralytics import YOLO\nimport torch\nimport gc\n\n# Clear GPU memory\ntorch.cuda.empty_cache()\ngc.collect()\n\n# Load a pre-trained YOLOv10n model\nmodel = YOLO('yolov10n.pt')\n\n# Optimized training configuration for Kaggle\nprint(\"Initiating model training...\")\nresults = model.train(\n    data=str(yolo_yaml_path),\n    epochs=15,\n    imgsz=640,\n    batch=16,  # Adjust: 8 (safer), 16 (balanced), 32 (if no OOM)\n    device=0,  # GPU\n    cache='disk',  # Critical for Kaggle: disk cache instead of RAM\n    workers=2,  # Reduce RAM usage\n    patience=5,  # Early stopping\n    save=True,\n    save_period=5,  # Save checkpoint every 5 epochs\n    project='/kaggle/working',  # Kaggle persistent directory\n    name='yolov10_training',\n    exist_ok=True,\n    pretrained=True,\n    optimizer='AdamW',\n    verbose=True,\n    seed=42,\n    deterministic=False,\n    amp=True,  # Automatic Mixed Precision - faster training\n    cos_lr=True,  # Cosine LR scheduler\n    close_mosaic=10,  # Disable mosaic in last 10 epochs\n    profile=False,  # Save memory\n    # Augmentation parameters (augment=True is deprecated, use individual params)\n    hsv_h=0.015,\n    hsv_s=0.7,\n    hsv_v=0.4,\n    degrees=0.0,\n    translate=0.1,\n    scale=0.5,\n    shear=0.0,\n    perspective=0.0,\n    flipud=0.0,\n    fliplr=0.5,\n    mosaic=1.0,\n    mixup=0.0,\n    copy_paste=0.0,\n)\n\nprint(\"Model training completed.\")\n\n# Clear memory\ndel model\ntorch.cuda.empty_cache()\ngc.collect()\n\n# Load best model\nbest_model = YOLO('/kaggle/working/yolov10_training/weights/best.pt')\nprint(f\"Best model loaded from: /kaggle/working/yolov10_training/weights/best.pt\")","metadata":{"trusted":true},"outputs":[{"name":"stdout","text":"Initiating model training...\nUltralytics 8.4.10 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 14913MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=disk, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/kaggle/working/data_yolo.yaml, degrees=0.0, deterministic=False, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=15, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10n.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=yolov10_training, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=5, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/yolov10_training, save_frames=False, save_json=False, save_period=5, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\nOverriding model.yaml nc=80 with nc=5\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1      9856  ultralytics.nn.modules.block.SCDown          [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1    249728  ultralytics.nn.modules.block.PSA             [256, 256]                    \n 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 13                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 16                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 19                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 20                  -1  1     18048  ultralytics.nn.modules.block.SCDown          [128, 128, 3, 2]              \n 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 22                  -1  1    282624  ultralytics.nn.modules.block.C2fCIB          [384, 256, 1, True, True]     \n 23        [16, 19, 22]  1    863278  ultralytics.nn.modules.head.v10Detect        [5, [64, 128, 256]]           \nYOLOv10n summary: 224 layers, 2,708,990 parameters, 2,708,974 gradients, 8.4 GFLOPs\n\nTransferred 493/595 items from pretrained weights\nFreezing layer 'model.23.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 276.8¬±301.2 MB/s, size: 181.5 KB)\n\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/train/labels... 26008 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 26008/26008 1.1Kit/s 24.0ss<0.1s\nWARNING ‚ö†Ô∏è \u001b[34m\u001b[1mtrain: \u001b[0mCache directory /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/train is not writable, cache not saved.\nWARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 205, len(boxes) = 56400. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\nWARNING ‚ö†Ô∏è \u001b[34m\u001b[1mtrain: \u001b[0mSkipping caching images to disk, directory not writable\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 286.7¬±260.2 MB/s, size: 430.3 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/val/labels... 7431 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 7431/7431 1.0Kit/s 7.4s<0.0s\nWARNING ‚ö†Ô∏è \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/val is not writable, cache not saved.\nWARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 37, len(boxes) = 16299. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\nWARNING ‚ö†Ô∏è \u001b[34m\u001b[1mval: \u001b[0mSkipping caching images to disk, directory not writable\nPlotting labels to /kaggle/working/yolov10_training/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.01, momentum=0.937) with parameter groups 95 weight(decay=0.0), 108 weight(decay=0.0005), 107 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1m/kaggle/working/yolov10_training\u001b[0m\nStarting training for 15 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       1/15      2.98G      1.464       2.14      1.462         45        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.0it/s 9:03<0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 1.7it/s 2:21<0.4s\n                   all       7431      16299      0.288      0.296      0.237      0.124\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       2/15      4.28G      1.436      1.799       1.44         17        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.1it/s 8:48<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 2.6it/s 1:30<0.2ss\n                   all       7431      16299      0.495      0.459       0.47      0.315\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       3/15      4.29G      1.359      1.611      1.381         35        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.1it/s 8:49<0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 2.7it/s 1:28<0.2ss\n                   all       7431      16299      0.459      0.387      0.376      0.225\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       4/15      4.31G      1.302      1.458      1.344         30        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.0it/s 8:54<0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 3.0it/s 1:19<0.2ss\n                   all       7431      16299      0.694      0.599      0.681      0.482\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       5/15      4.32G      1.258      1.347      1.317         27        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.1it/s 8:49<0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 2.9it/s 1:19<0.2ss\n                   all       7431      16299      0.719      0.632      0.716       0.51\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       6/15      4.34G      1.237      1.197      1.343         22        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.0it/s 8:57<0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 2.7it/s 1:27<0.2ss\n                   all       7431      16299      0.754      0.645      0.732      0.532\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       7/15      4.36G      1.194      1.108      1.309         11        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 2.8it/s 9:34<0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 2.4it/s 1:37<0.2ss\n                   all       7431      16299      0.756      0.677      0.766       0.56\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       8/15      4.38G      1.169      1.036      1.284          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 2.8it/s 9:34<0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 2.3it/s 1:39<0.2ss\n                   all       7431      16299      0.771      0.688      0.779      0.578\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       9/15      4.39G      1.144     0.9743      1.266         21        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 2.9it/s 9:23<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 2.7it/s 1:27<0.2ss\n                   all       7431      16299      0.808      0.712      0.808      0.603\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      10/15       4.4G       1.12     0.9205      1.238         25        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.1it/s 8:52<0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 2.9it/s 1:21<0.2ss\n                   all       7431      16299      0.833      0.721      0.822       0.62\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      11/15      4.42G      1.095       0.87      1.226         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.1it/s 8:39<0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 2.7it/s 1:25<0.2ss\n                   all       7431      16299      0.827      0.745      0.834      0.632\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      12/15      4.44G      1.077     0.8413      1.212         11        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.1it/s 8:49<0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 2.6it/s 1:31<0.2ss\n                   all       7431      16299      0.828      0.752      0.841      0.641\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      13/15      4.45G      1.063     0.8131      1.203         15        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 2.8it/s 9:32<0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 2.5it/s 1:33<0.2ss\n                   all       7431      16299      0.836      0.755      0.846      0.646\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      14/15      4.47G      1.055     0.7937      1.197         35        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 2.9it/s 9:29<0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 2.5it/s 1:32<0.2ss\n                   all       7431      16299      0.844      0.759       0.85      0.649\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      15/15      4.48G      1.044      0.784       1.19         19        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 2.8it/s 9:31<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 2.6it/s 1:30<0.2ss\n                   all       7431      16299      0.834      0.763      0.851      0.651\n\n15 epochs completed in 2.666 hours.\nOptimizer stripped from /kaggle/working/yolov10_training/weights/last.pt, 5.7MB\nOptimizer stripped from /kaggle/working/yolov10_training/weights/best.pt, 5.7MB\n\nValidating /kaggle/working/yolov10_training/weights/best.pt...\nUltralytics 8.4.10 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 14913MiB)\nYOLOv10n summary (fused): 102 layers, 2,266,143 parameters, 0 gradients, 6.5 GFLOPs\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 2.6it/s 1:28<0.2ss\n                   all       7431      16299      0.836      0.762      0.851      0.651\n                   bus       1967       3248      0.838      0.751      0.845      0.588\n                   car       3695       8177      0.839      0.726      0.834       0.55\n                pickup       2048       2383      0.844      0.783      0.866      0.659\n                 truck       1586       2017      0.872      0.767      0.862      0.692\n                   van        455        474      0.785      0.784      0.846      0.765\nSpeed: 0.2ms preprocess, 1.8ms inference, 0.0ms loss, 0.2ms postprocess per image\nResults saved to \u001b[1m/kaggle/working/yolov10_training\u001b[0m\nModel training completed.\nBest model loaded from: /kaggle/working/yolov10_training/weights/best.pt\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"from ultralytics import YOLO\nfrom pathlib import Path\n\n# Paths\nWORKING_DIR = Path(\"/kaggle/working\")\nbest_model_path = WORKING_DIR / \"yolov10_training/weights/best.pt\"\n\n# Load the trained model\nprint(f\"üìÇ Loading model: {best_model_path}\")\nmodel = YOLO(str(best_model_path))\n\n# Validate\nprint(\"\\nüîç Validating YOLOv10n model...\")\nmetrics = model.val()\n\n# Display all metrics\nprint(f\"\\nüìä Validation Results:\")\nprint(f\"   mAP50:     {metrics.box.map50:.4f}\")\nprint(f\"   mAP50-95:  {metrics.box.map:.4f}\")\nprint(f\"   Precision: {metrics.box.mp:.4f}\")\nprint(f\"   Recall:    {metrics.box.mr:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-03T02:07:01.072248Z","iopub.execute_input":"2026-02-03T02:07:01.072549Z","iopub.status.idle":"2026-02-03T02:08:47.761341Z","shell.execute_reply.started":"2026-02-03T02:07:01.072519Z","shell.execute_reply":"2026-02-03T02:08:47.760248Z"}},"outputs":[{"name":"stdout","text":"üìÇ Loading model: /kaggle/working/yolov10_training/weights/best.pt\n\nüîç Validating YOLOv10n model...\nUltralytics 8.4.10 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 14913MiB)\nYOLOv10n summary (fused): 102 layers, 2,266,143 parameters, 0 gradients, 6.5 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 275.2¬±218.3 MB/s, size: 334.8 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/val/labels... 7431 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 7431/7431 712.8it/s 10.4s<0.0s\nWARNING ‚ö†Ô∏è \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/val is not writable, cache not saved.\nWARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 37, len(boxes) = 16299. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 465/465 5.1it/s 1:31<0.1ss\n                   all       7431      16299      0.836      0.762       0.85       0.65\n                   bus       1967       3248      0.839       0.75      0.845      0.587\n                   car       3695       8177       0.84      0.726      0.834       0.55\n                pickup       2048       2383      0.844      0.782      0.865      0.658\n                 truck       1586       2017      0.871      0.768      0.862      0.692\n                   van        455        474      0.788      0.783      0.846      0.765\nSpeed: 0.8ms preprocess, 2.8ms inference, 0.0ms loss, 0.2ms postprocess per image\nResults saved to \u001b[1m/kaggle/working/runs/detect/val2\u001b[0m\n\nüìä Validation Results:\n   mAP50:     0.8503\n   mAP50-95:  0.6505\n   Precision: 0.8365\n   Recall:    0.7617\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"import yaml\nfrom pathlib import Path\n\n# Dataset root (read-only)\nDATASET_DIR = Path(\"/kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles\")\n# Writable directory\nWORKING_DIR = Path(\"/kaggle/working\")\n\n# ---- Read existing data.yaml ----\noriginal_yaml = DATASET_DIR / \"data.yaml\"\nif not original_yaml.exists():\n    raise FileNotFoundError(\"‚ùå data.yaml not found in dataset directory\")\n\nwith open(original_yaml, \"r\") as f:\n    original_data = yaml.safe_load(f)\n\n# Extract class info\nclasses = original_data.get(\"names\", [])\nnc = original_data.get(\"nc\", len(classes))\n\nif not classes or nc == 0:\n    raise ValueError(\"‚ùå No classes found in original data.yaml\")\n\n# ---- Create new YOLO config ----\nyolo_data_config = {\n    \"path\": str(DATASET_DIR.resolve()),\n    \"train\": \"train/images\",\n    \"val\": \"val/images\",\n    \"test\": \"test/images\",\n    \"nc\": nc,\n    \"names\": classes\n}\n\n# Save new YAML\nyolo_yaml_path = WORKING_DIR / \"data_yolo.yaml\"\nwith open(yolo_yaml_path, \"w\") as f:\n    yaml.dump(yolo_data_config, f, sort_keys=False)\n\n# Print confirmation\nprint(f\"‚úÖ data_yolo.yaml file saved to: {yolo_yaml_path}\\n\")\nprint(\"Content of data_yolo.yaml:\")\nprint(yolo_yaml_path.read_text())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-03T07:25:15.201384Z","iopub.execute_input":"2026-02-03T07:25:15.202069Z","iopub.status.idle":"2026-02-03T07:25:15.247224Z","shell.execute_reply.started":"2026-02-03T07:25:15.202035Z","shell.execute_reply":"2026-02-03T07:25:15.246618Z"}},"outputs":[{"name":"stdout","text":"‚úÖ data_yolo.yaml file saved to: /kaggle/working/data_yolo.yaml\n\nContent of data_yolo.yaml:\npath: /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles\ntrain: train/images\nval: val/images\ntest: test/images\nnc: 5\nnames:\n- bus\n- car\n- pickup\n- truck\n- van\n\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from ultralytics import YOLO\nimport torch\nimport gc\n\n# Clear GPU memory\ntorch.cuda.empty_cache()\ngc.collect()\n\n# Load a pre-trained YOLOv11n model\nmodel = YOLO('yolo11n.pt')\n\n# Train the model\nprint(\"üöÄ Initiating YOLOv11 model training...\")\nresults = model.train(\n    data=str(yolo_yaml_path), \n    epochs=20, \n    imgsz=640, \n    batch=16,  # Adjust: 8 (safer), 16 (balanced), 24-32 (if no OOM)\n    device=0,  # Enable GPU - CRITICAL for Kaggle!\n    cache='disk',  # Use disk cache instead of RAM (Kaggle has limited RAM)\n    workers=2,  # Reduce RAM usage from data loading\n    patience=5,  # Early stopping to save GPU hours\n    save=True,\n    save_period=5,  # Save checkpoint every 5 epochs (safety for timeouts)\n    project='/kaggle/working/yolov11_training',  # Kaggle persistent directory\n    name='vehicle_detection',\n    exist_ok=True,\n    pretrained=True,\n    optimizer='AdamW',  # Often better than SGD\n    verbose=True,\n    seed=42,\n    deterministic=False,  # Faster training\n    amp=True,  # Automatic Mixed Precision - faster on T4/P100\n    cos_lr=True,  # Cosine learning rate scheduler\n    close_mosaic=10,  # Disable mosaic in last 10 epochs for better accuracy\n    profile=False,  # Disable profiling to save memory\n    plots=True,  # Generate training plots\n    # Augmentation parameters (augment=True is deprecated)\n    hsv_h=0.015,  # Hue augmentation\n    hsv_s=0.7,    # Saturation augmentation\n    hsv_v=0.4,    # Value augmentation\n    degrees=0.0,  # Rotation (0-10 for vehicles)\n    translate=0.1,  # Translation\n    scale=0.5,    # Scale augmentation\n    shear=0.0,    # Shear\n    perspective=0.0,  # Perspective\n    flipud=0.0,   # Vertical flip (usually 0 for vehicles)\n    fliplr=0.5,   # Horizontal flip (0.5 for vehicles)\n    mosaic=1.0,   # Mosaic augmentation\n    mixup=0.0,    # Mixup augmentation\n    copy_paste=0.0,  # Copy-paste augmentation\n)\nprint(\"‚úÖ YOLOv11 model training completed.\")\n\n# Clear memory after training\ndel model\ntorch.cuda.empty_cache()\ngc.collect()\n\n# Load the best model for validation/inference\nprint(\"üì¶ Loading best trained model...\")\nbest_model = YOLO('/kaggle/working/yolov11_training/vehicle_detection/weights/best.pt')\nprint(f\"‚úÖ Best model loaded from: /kaggle/working/yolov11_training/vehicle_detection/weights/best.pt\")\n\n# Optional: Validate the model\nprint(\"üìä Validating model performance...\")\nmetrics = best_model.val()\nprint(f\"mAP50-95: {metrics.box.map}\")\nprint(f\"mAP50: {metrics.box.map50}\")\nprint(f\"mAP75: {metrics.box.map75}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-03T07:27:09.008809Z","iopub.execute_input":"2026-02-03T07:27:09.009421Z","iopub.status.idle":"2026-02-03T10:50:27.978665Z","shell.execute_reply.started":"2026-02-03T07:27:09.009388Z","shell.execute_reply":"2026-02-03T10:50:27.977826Z"}},"outputs":[{"name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file ‚úÖ \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo11n.pt to 'yolo11n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.4MB 62.1MB/s 0.1s\nüöÄ Initiating YOLOv11 model training...\nUltralytics 8.4.10 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 14913MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=disk, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/kaggle/working/data_yolo.yaml, degrees=0.0, deterministic=False, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=vehicle_detection, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=5, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/yolov11_training, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/yolov11_training/vehicle_detection, save_frames=False, save_json=False, save_period=5, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 755.1KB 15.1MB/s 0.0s\nOverriding model.yaml nc=80 with nc=5\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n 23        [16, 19, 22]  1    431647  ultralytics.nn.modules.head.Detect           [5, 16, None, [64, 128, 256]] \nYOLO11n summary: 182 layers, 2,590,815 parameters, 2,590,799 gradients, 6.4 GFLOPs\n\nTransferred 448/499 items from pretrained weights\nFreezing layer 'model.23.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26n.pt to 'yolo26n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.3MB 17.8MB/s 0.3s.2s<0.1s\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 1.0¬±0.5 ms, read: 10.5¬±14.8 MB/s, size: 146.0 KB)\n\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/train/labels... 26008 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 26008/26008 131.8it/s 3:17<0.0s\nWARNING ‚ö†Ô∏è \u001b[34m\u001b[1mtrain: \u001b[0mCache directory /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/train is not writable, cache not saved.\nWARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 205, len(boxes) = 56400. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\nWARNING ‚ö†Ô∏è \u001b[34m\u001b[1mtrain: \u001b[0mSkipping caching images to disk, directory not writable\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.7¬±0.6 ms, read: 17.9¬±13.1 MB/s, size: 397.6 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/val/labels... 7431 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 7431/7431 151.8it/s 48.9s<0.0s\nWARNING ‚ö†Ô∏è \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/val is not writable, cache not saved.\nWARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 37, len(boxes) = 16299. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\nWARNING ‚ö†Ô∏è \u001b[34m\u001b[1mval: \u001b[0mSkipping caching images to disk, directory not writable\nPlotting labels to /kaggle/working/yolov11_training/vehicle_detection/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.01, momentum=0.937) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1m/kaggle/working/yolov11_training/vehicle_detection\u001b[0m\nStarting training for 20 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       1/20      2.33G      1.319      1.767      1.468         45        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 2.8it/s 9:38<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 1.7it/s 2:15<0.3ss\n                   all       7431      16299      0.308      0.442      0.286       0.15\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       2/20      3.54G       1.26      1.529      1.422         17        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.3it/s 8:13<0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 2.9it/s 1:19<0.2ss\n                   all       7431      16299      0.431      0.475      0.442       0.26\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       3/20      3.54G      1.197      1.387      1.376         35        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.3it/s 8:15<0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 3.0it/s 1:19<0.2ss\n                   all       7431      16299       0.59      0.556      0.555      0.366\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       4/20      3.57G      1.154      1.265      1.341         30        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.3it/s 8:14<0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 3.0it/s 1:16<0.2ss\n                   all       7431      16299      0.675      0.614      0.683      0.467\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       5/20      3.58G      1.111      1.181       1.31         27        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.3it/s 8:11<0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 2.9it/s 1:20<0.2ss\n                   all       7431      16299      0.697      0.653      0.712      0.503\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       6/20       3.6G      1.081      1.117      1.289         33        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.3it/s 8:18<0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 3.0it/s 1:19<0.2ss\n                   all       7431      16299      0.754      0.671      0.742      0.526\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       7/20       3.6G      1.064      1.067      1.273         55        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.3it/s 8:14<0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 3.0it/s 1:19<0.2ss\n                   all       7431      16299      0.774      0.694      0.779      0.567\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       8/20      3.63G      1.044      1.024      1.259         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.3it/s 8:16<0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 3.0it/s 1:17<0.2ss\n                   all       7431      16299      0.789      0.715      0.793      0.577\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       9/20      3.64G      1.027     0.9846      1.245         37        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.3it/s 8:17<0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 3.0it/s 1:18<0.2ss\n                   all       7431      16299        0.8      0.716      0.807      0.596\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      10/20      3.66G      1.006     0.9507      1.232         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.3it/s 8:18<0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 3.0it/s 1:19<0.2ss\n                   all       7431      16299      0.804      0.739      0.821       0.61\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      11/20      3.66G      1.033     0.8491      1.254         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.3it/s 8:11<0.5s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 3.0it/s 1:18<0.2ss\n                   all       7431      16299      0.824      0.748      0.831       0.62\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      12/20      3.69G      1.012     0.8062      1.238         11        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.4it/s 8:03<0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 3.0it/s 1:19<0.2ss\n                   all       7431      16299      0.844      0.753      0.844      0.636\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      13/20      3.69G     0.9933     0.7683       1.22         17        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.3it/s 8:09<0.5s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 3.0it/s 1:18<0.2ss\n                   all       7431      16299      0.835      0.765      0.851      0.643\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      14/20      3.71G     0.9785     0.7377      1.208         35        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.3it/s 8:10<0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 3.0it/s 1:18<0.2ss\n                   all       7431      16299      0.853      0.761      0.854      0.649\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      15/20      3.72G      0.963     0.7118      1.192         19        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.3it/s 8:08<0.5s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 2.9it/s 1:19<0.2ss\n                   all       7431      16299      0.845      0.778       0.86      0.655\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      16/20      3.74G     0.9498     0.6875      1.183         18        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.3it/s 8:10<0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 3.0it/s 1:17<0.2ss\n                   all       7431      16299      0.846      0.785      0.864      0.661\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      17/20      3.75G     0.9401     0.6707      1.176         17        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.3it/s 8:14<0.5s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 2.9it/s 1:19<0.2ss\n                   all       7431      16299      0.852      0.781      0.868      0.665\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      18/20      3.77G     0.9335     0.6541      1.168         15        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.3it/s 8:11<0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 3.0it/s 1:19<0.2ss\n                   all       7431      16299      0.852      0.781      0.869      0.667\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      19/20      3.79G     0.9244     0.6423      1.164         12        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.3it/s 8:15<0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 2.9it/s 1:20<0.2ss\n                   all       7431      16299      0.862      0.779      0.869      0.667\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      20/20       3.8G     0.9207     0.6399      1.163         24        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1626/1626 3.3it/s 8:06<0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 3.0it/s 1:17<0.2ss\n                   all       7431      16299      0.861      0.779       0.87      0.668\n\n20 epochs completed in 3.214 hours.\nOptimizer stripped from /kaggle/working/yolov11_training/vehicle_detection/weights/last.pt, 5.4MB\nOptimizer stripped from /kaggle/working/yolov11_training/vehicle_detection/weights/best.pt, 5.4MB\n\nValidating /kaggle/working/yolov11_training/vehicle_detection/weights/best.pt...\nUltralytics 8.4.10 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 14913MiB)\nYOLO11n summary (fused): 101 layers, 2,583,127 parameters, 0 gradients, 6.3 GFLOPs\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 233/233 2.9it/s 1:20<0.2ss\n                   all       7431      16299      0.864      0.776       0.87      0.668\n                   bus       1967       3248      0.871      0.753      0.865      0.604\n                   car       3695       8177      0.861      0.741      0.853      0.565\n                pickup       2048       2383      0.865      0.812      0.886      0.674\n                 truck       1586       2017      0.903      0.768      0.879      0.711\n                   van        455        474       0.82      0.808      0.865      0.785\nSpeed: 0.2ms preprocess, 1.6ms inference, 0.0ms loss, 1.0ms postprocess per image\nResults saved to \u001b[1m/kaggle/working/yolov11_training/vehicle_detection\u001b[0m\n‚úÖ YOLOv11 model training completed.\nüì¶ Loading best trained model...\n‚úÖ Best model loaded from: /kaggle/working/yolov11_training/vehicle_detection/weights/best.pt\nüìä Validating model performance...\nUltralytics 8.4.10 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 14913MiB)\nYOLO11n summary (fused): 101 layers, 2,583,127 parameters, 0 gradients, 6.3 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 74.7¬±81.5 MB/s, size: 90.5 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/val/labels... 7431 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 7431/7431 481.2it/s 15.4s<0.0s\nWARNING ‚ö†Ô∏è \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/val is not writable, cache not saved.\nWARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 37, len(boxes) = 16299. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 465/465 5.6it/s 1:23<0.1sss\n                   all       7431      16299       0.86      0.781       0.87      0.668\n                   bus       1967       3248      0.864      0.756      0.865      0.604\n                   car       3695       8177      0.857      0.748      0.853      0.566\n                pickup       2048       2383      0.861      0.816      0.886      0.673\n                 truck       1586       2017      0.898       0.77      0.879      0.711\n                   van        455        474      0.821      0.814      0.864      0.785\nSpeed: 0.7ms preprocess, 2.7ms inference, 0.0ms loss, 0.9ms postprocess per image\nResults saved to \u001b[1m/kaggle/working/runs/detect/val\u001b[0m\nmAP50-95: 0.667889678946715\nmAP50: 0.8697046329787067\nmAP75: 0.729831382121437\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from ultralytics import YOLO\nfrom pathlib import Path\n\n# Paths\nWORKING_DIR = Path(\"/kaggle/working\")\nbest_model_path = WORKING_DIR / \"yolov11_training/vehicle_detection/weights/best.pt\"\n\n# Load the trained model\nprint(f\"üìÇ Loading model: {best_model_path}\")\nmodel = YOLO(str(best_model_path))\n\n# Validate\nprint(\"\\nüîç Validating YOLOv11 model...\")  # Fixed comment\nmetrics = model.val()\n\n# Display all metrics\nprint(f\"\\nüìä Validation Results:\")\nprint(f\"   mAP50:     {metrics.box.map50:.4f}\")\nprint(f\"   mAP50-95:  {metrics.box.map:.4f}\")\nprint(f\"   Precision: {metrics.box.mp:.4f}\")\nprint(f\"   Recall:    {metrics.box.mr:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-03T10:50:27.980472Z","iopub.execute_input":"2026-02-03T10:50:27.980964Z","iopub.status.idle":"2026-02-03T10:52:10.194501Z","shell.execute_reply.started":"2026-02-03T10:50:27.980929Z","shell.execute_reply":"2026-02-03T10:52:10.193677Z"}},"outputs":[{"name":"stdout","text":"üìÇ Loading model: /kaggle/working/yolov11_training/vehicle_detection/weights/best.pt\n\nüîç Validating YOLOv11 model...\nUltralytics 8.4.10 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 14913MiB)\nYOLO11n summary (fused): 101 layers, 2,583,127 parameters, 0 gradients, 6.3 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 217.7¬±274.5 MB/s, size: 341.2 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/val/labels... 7431 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 7431/7431 566.3it/s 13.1s0.1s\nWARNING ‚ö†Ô∏è \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/val is not writable, cache not saved.\nWARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 37, len(boxes) = 16299. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 465/465 5.6it/s 1:24<0.1sss\n                   all       7431      16299       0.86      0.781       0.87      0.668\n                   bus       1967       3248      0.864      0.756      0.865      0.604\n                   car       3695       8177      0.857      0.748      0.853      0.566\n                pickup       2048       2383      0.861      0.816      0.886      0.673\n                 truck       1586       2017      0.898       0.77      0.879      0.711\n                   van        455        474      0.821      0.814      0.864      0.785\nSpeed: 0.7ms preprocess, 2.6ms inference, 0.0ms loss, 0.9ms postprocess per image\nResults saved to \u001b[1m/kaggle/working/runs/detect/val2\u001b[0m\n\nüìä Validation Results:\n   mAP50:     0.8697\n   mAP50-95:  0.6679\n   Precision: 0.8602\n   Recall:    0.7807\n","output_type":"stream"}],"execution_count":5}]}