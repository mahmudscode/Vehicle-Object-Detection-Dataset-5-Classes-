{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24cc6524",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T10:56:53.678719Z",
     "iopub.status.busy": "2026-02-03T10:56:53.677871Z",
     "iopub.status.idle": "2026-02-03T10:56:54.654905Z",
     "shell.execute_reply": "2026-02-03T10:56:54.653879Z"
    },
    "papermill": {
     "duration": 0.984088,
     "end_time": "2026-02-03T10:56:54.657290",
     "exception": false,
     "start_time": "2026-02-03T10:56:53.673202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /kaggle/input/vehicle-object-detection-dataset-5-classes\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"hammadjavaid/vehicle-object-detection-dataset-5-classes\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e0e5268",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T10:56:54.665022Z",
     "iopub.status.busy": "2026-02-03T10:56:54.664643Z",
     "iopub.status.idle": "2026-02-03T10:56:54.673978Z",
     "shell.execute_reply": "2026-02-03T10:56:54.673230Z"
    },
    "papermill": {
     "duration": 0.01499,
     "end_time": "2026-02-03T10:56:54.675503",
     "exception": false,
     "start_time": "2026-02-03T10:56:54.660513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of '/kaggle/input/vehicle-object-detection-dataset-5-classes':\n",
      "vehicles\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dataset_path = \"/kaggle/input/vehicle-object-detection-dataset-5-classes\"\n",
    "\n",
    "# Check if the directory exists\n",
    "if os.path.exists(dataset_path):\n",
    "    print(f\"Contents of '{dataset_path}':\")\n",
    "    for item in os.listdir(dataset_path):\n",
    "        print(item)\n",
    "else:\n",
    "    print(f\"Error: Directory '{dataset_path}' not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db6f69c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T10:56:54.682750Z",
     "iopub.status.busy": "2026-02-03T10:56:54.682497Z",
     "iopub.status.idle": "2026-02-03T10:56:54.708423Z",
     "shell.execute_reply": "2026-02-03T10:56:54.707805Z"
    },
    "papermill": {
     "duration": 0.031538,
     "end_time": "2026-02-03T10:56:54.709962",
     "exception": false,
     "start_time": "2026-02-03T10:56:54.678424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring dataset structure in: /kaggle/input/vehicle-object-detection-dataset-5-classes\n",
      "\n",
      "Contents of '/kaggle/input/vehicle-object-detection-dataset-5-classes':\n",
      "  ğŸ“ vehicles/\n",
      "  Contents of '/kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles':\n",
      "    ğŸ“„ data.yaml\n",
      "    ğŸ“ val/\n",
      "    Contents of '/kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/val':\n",
      "      ğŸ“ labels/\n",
      "      ğŸ“ images/\n",
      "    ğŸ“ test/\n",
      "    Contents of '/kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/test':\n",
      "      ğŸ“ labels/\n",
      "      ğŸ“ images/\n",
      "    ğŸ“ train/\n",
      "    Contents of '/kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/train':\n",
      "      ğŸ“ labels/\n",
      "      ğŸ“ images/\n",
      "\n",
      "âœ… Found dataset directory: /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/val\n",
      "\n",
      "Contents of dataset directory:\n",
      "  - labels\n",
      "  - images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# First, let's check what's actually in the dataset path\n",
    "print(f\"Exploring dataset structure in: {dataset_path}\\n\")\n",
    "\n",
    "# Function to explore directory structure\n",
    "def explore_directory(path, max_depth=5, current_depth=0):\n",
    "    if current_depth > max_depth:\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        items = os.listdir(path)\n",
    "        indent = \"  \" * current_depth\n",
    "        print(f\"{indent}Contents of '{path}':\")\n",
    "        \n",
    "        for item in items:\n",
    "            item_path = os.path.join(path, item)\n",
    "            if os.path.isdir(item_path):\n",
    "                print(f\"{indent}  ğŸ“ {item}/\")\n",
    "                if current_depth < max_depth:\n",
    "                    explore_directory(item_path, max_depth, current_depth + 1)\n",
    "            else:\n",
    "                print(f\"{indent}  ğŸ“„ {item}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{indent}Error accessing {path}: {e}\")\n",
    "\n",
    "explore_directory(dataset_path, max_depth=2)\n",
    "\n",
    "# Now try to find the correct dataset subdirectory\n",
    "possible_paths = [\n",
    "    os.path.join(dataset_path, 'dataset'),\n",
    "    dataset_path,  # Sometimes the dataset folder IS the root\n",
    "]\n",
    "\n",
    "dataset_sub_path = None\n",
    "for path in possible_paths:\n",
    "    if os.path.exists(path):\n",
    "        # Check if this path has 'images' and 'labels' folders\n",
    "        contents = os.listdir(path)\n",
    "        if 'images' in contents and 'labels' in contents:\n",
    "            dataset_sub_path = path\n",
    "            print(f\"\\nâœ… Found dataset directory: {dataset_sub_path}\")\n",
    "            break\n",
    "\n",
    "if dataset_sub_path is None:\n",
    "    # If still not found, search for images and labels folders\n",
    "    for root, dirs, files in os.walk(dataset_path):\n",
    "        if 'images' in dirs and 'labels' in dirs:\n",
    "            dataset_sub_path = root\n",
    "            print(f\"\\nâœ… Found dataset directory: {dataset_sub_path}\")\n",
    "            break\n",
    "\n",
    "if dataset_sub_path:\n",
    "    print(f\"\\nContents of dataset directory:\")\n",
    "    for item in os.listdir(dataset_sub_path):\n",
    "        print(f\"  - {item}\")\n",
    "else:\n",
    "    print(\"\\nâŒ Could not find dataset directory with 'images' and 'labels' folders\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2654b98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T10:56:54.716941Z",
     "iopub.status.busy": "2026-02-03T10:56:54.716668Z",
     "iopub.status.idle": "2026-02-03T10:57:00.576499Z",
     "shell.execute_reply": "2026-02-03T10:57:00.575561Z"
    },
    "papermill": {
     "duration": 5.865507,
     "end_time": "2026-02-03T10:57:00.578417",
     "exception": false,
     "start_time": "2026-02-03T10:56:54.712910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\r\n",
      "  Downloading ultralytics-8.4.10-py3-none-any.whl.metadata (38 kB)\r\n",
      "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\r\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\r\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\r\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\r\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.5)\r\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.15.3)\r\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\r\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\r\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\r\n",
      "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\r\n",
      "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\r\n",
      "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (26.0rc2)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.6.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2026.1.4)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.3)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\r\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.10.0)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\r\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\r\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\r\n",
      "Downloading ultralytics-8.4.10-py3-none-any.whl (1.2 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\r\n",
      "Installing collected packages: ultralytics-thop, ultralytics\r\n",
      "Successfully installed ultralytics-8.4.10 ultralytics-thop-2.0.18\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5756796",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T10:57:00.587782Z",
     "iopub.status.busy": "2026-02-03T10:57:00.587094Z",
     "iopub.status.idle": "2026-02-03T10:57:04.899158Z",
     "shell.execute_reply": "2026-02-03T10:57:04.898444Z"
    },
    "papermill": {
     "duration": 4.318494,
     "end_time": "2026-02-03T10:57:04.900692",
     "exception": false,
     "start_time": "2026-02-03T10:57:00.582198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "Ultralytics version: 8.4.10\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "\n",
    "print(f\"Ultralytics version: {ultralytics.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b9dcafa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T10:57:04.909378Z",
     "iopub.status.busy": "2026-02-03T10:57:04.908972Z",
     "iopub.status.idle": "2026-02-03T10:57:05.383642Z",
     "shell.execute_reply": "2026-02-03T10:57:05.382864Z"
    },
    "papermill": {
     "duration": 0.481087,
     "end_time": "2026-02-03T10:57:05.385459",
     "exception": false,
     "start_time": "2026-02-03T10:57:04.904372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Feb  3 10:57:04 2026       \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 580.105.08             Driver Version: 580.105.08     CUDA Version: 13.0     |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                        |               MIG M. |\r\n",
      "|=========================================+========================+======================|\r\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   49C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\r\n",
      "| N/A   49C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "\r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                              |\r\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\r\n",
      "|        ID   ID                                                               Usage      |\r\n",
      "|=========================================================================================|\r\n",
      "|  No running processes found                                                             |\r\n",
      "+-----------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f24368f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T10:57:05.394713Z",
     "iopub.status.busy": "2026-02-03T10:57:05.394000Z",
     "iopub.status.idle": "2026-02-03T10:57:05.411099Z",
     "shell.execute_reply": "2026-02-03T10:57:05.410294Z"
    },
    "papermill": {
     "duration": 0.023672,
     "end_time": "2026-02-03T10:57:05.412964",
     "exception": false,
     "start_time": "2026-02-03T10:57:05.389292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… data_yolo.yaml file saved to: /kaggle/working/data_yolo.yaml\n",
      "\n",
      "Content of data_yolo.yaml:\n",
      "path: /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles\n",
      "train: train/images\n",
      "val: val/images\n",
      "test: test/images\n",
      "nc: 5\n",
      "names:\n",
      "- bus\n",
      "- car\n",
      "- pickup\n",
      "- truck\n",
      "- van\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "# Dataset root (read-only)\n",
    "DATASET_DIR = Path(\"/kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles\")\n",
    "\n",
    "# Writable directory\n",
    "WORKING_DIR = Path(\"/kaggle/working\")\n",
    "\n",
    "# ---- Read existing data.yaml ----\n",
    "original_yaml = DATASET_DIR / \"data.yaml\"\n",
    "\n",
    "if not original_yaml.exists():\n",
    "    raise FileNotFoundError(\"âŒ data.yaml not found in dataset directory\")\n",
    "\n",
    "with open(original_yaml, \"r\") as f:\n",
    "    original_data = yaml.safe_load(f)\n",
    "\n",
    "# Extract class info\n",
    "classes = original_data.get(\"names\", [])\n",
    "nc = original_data.get(\"nc\", len(classes))\n",
    "\n",
    "if not classes or nc == 0:\n",
    "    raise ValueError(\"âŒ No classes found in original data.yaml\")\n",
    "\n",
    "# ---- Create new YOLO config ----\n",
    "yolo_data_config = {\n",
    "    \"path\": str(DATASET_DIR.resolve()),\n",
    "    \"train\": \"train/images\",\n",
    "    \"val\": \"val/images\",\n",
    "    \"test\": \"test/images\",\n",
    "    \"nc\": nc,\n",
    "    \"names\": classes\n",
    "}\n",
    "\n",
    "# Save new YAML\n",
    "yolo_yaml_path = WORKING_DIR / \"data_yolo.yaml\"\n",
    "with open(yolo_yaml_path, \"w\") as f:\n",
    "    yaml.dump(yolo_data_config, f, sort_keys=False)\n",
    "\n",
    "# Print confirmation\n",
    "print(f\"âœ… data_yolo.yaml file saved to: {yolo_yaml_path}\\n\")\n",
    "print(\"Content of data_yolo.yaml:\")\n",
    "print(yolo_yaml_path.read_text())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b887a857",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T10:57:05.422449Z",
     "iopub.status.busy": "2026-02-03T10:57:05.421797Z",
     "iopub.status.idle": "2026-02-03T13:31:22.418809Z",
     "shell.execute_reply": "2026-02-03T13:31:22.418044Z"
    },
    "papermill": {
     "duration": 9257.003611,
     "end_time": "2026-02-03T13:31:22.420545",
     "exception": false,
     "start_time": "2026-02-03T10:57:05.416934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolov8n.pt to 'yolov8n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 6.2MB 78.2MB/s 0.1s\n",
      "Initiating model training...\n",
      "Ultralytics 8.4.10 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 14913MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=disk, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/kaggle/working/data_yolo.yaml, degrees=0.0, deterministic=False, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=15, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=yolov8_training, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=5, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/yolov8_training, save_frames=False, save_json=False, save_period=5, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
      "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 15.6MB/s 0.0s\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752287  ultralytics.nn.modules.head.Detect           [5, 16, None, [64, 128, 256]] \n",
      "Model summary: 130 layers, 3,011,823 parameters, 3,011,807 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26n.pt to 'yolo26n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.3MB 63.7MB/s 0.1s\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.5Â±0.2 ms, read: 8.5Â±5.3 MB/s, size: 146.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/train/labels... 26008 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 26008/26008 214.1it/s 2:01\n",
      "WARNING âš ï¸ \u001b[34m\u001b[1mtrain: \u001b[0mCache directory /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/train is not writable, cache not saved.\n",
      "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 205, len(boxes) = 56400. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "WARNING âš ï¸ \u001b[34m\u001b[1mtrain: \u001b[0mSkipping caching images to disk, directory not writable\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.2Â±0.2 ms, read: 19.0Â±13.1 MB/s, size: 397.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/val/labels... 7431 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 7431/7431 207.8it/s 35.8s\n",
      "WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/val is not writable, cache not saved.\n",
      "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 37, len(boxes) = 16299. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mSkipping caching images to disk, directory not writable\n",
      "Plotting labels to /kaggle/working/yolov8_training/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.01, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m/kaggle/working/yolov8_training\u001b[0m\n",
      "Starting training for 15 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/15      2.06G      1.304      1.724      1.446         45        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.0it/s 9:05\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.7it/s 1:27\n",
      "                   all       7431      16299      0.229      0.262      0.222      0.121\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/15      3.37G      1.248      1.485      1.408         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.2it/s 8:27\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.8it/s 1:23\n",
      "                   all       7431      16299      0.505      0.485       0.48        0.3\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/15      3.38G      1.182      1.338      1.357         35        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.3it/s 8:20\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.9it/s 1:22\n",
      "                   all       7431      16299      0.649      0.553      0.606      0.405\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/15       3.4G      1.133      1.222      1.322         30        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.2it/s 8:21\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.8it/s 1:22\n",
      "                   all       7431      16299      0.719      0.632       0.71      0.489\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/15      3.41G      1.098       1.14      1.297         27        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.2it/s 8:22\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.9it/s 1:21\n",
      "                   all       7431      16299      0.727      0.667      0.742      0.523\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/15      3.43G      1.103       1.01      1.324         22        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.2it/s 8:33\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.8it/s 1:22\n",
      "                   all       7431      16299      0.764      0.667      0.756      0.535\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/15      3.45G      1.075     0.9406      1.298         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.2it/s 8:22\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.9it/s 1:20\n",
      "                   all       7431      16299      0.792        0.7      0.793      0.578\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/15      3.47G       1.05      0.886      1.274          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.2it/s 8:32\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.8it/s 1:22\n",
      "                   all       7431      16299      0.799      0.732      0.813      0.604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/15      3.48G      1.026      0.833      1.257         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.2it/s 8:33\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.8it/s 1:22\n",
      "                   all       7431      16299      0.803      0.736      0.822      0.614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/15       3.5G      1.004     0.7888      1.233         25        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.2it/s 8:25\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.8it/s 1:22\n",
      "                   all       7431      16299      0.834       0.75      0.838       0.63\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/15      3.51G     0.9835     0.7546      1.221         34        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.2it/s 8:25\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.8it/s 1:22\n",
      "                   all       7431      16299      0.836      0.765      0.848      0.643\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/15      3.54G     0.9692     0.7241      1.206         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.2it/s 8:34\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.8it/s 1:24\n",
      "                   all       7431      16299      0.839      0.771      0.853       0.65\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/15      3.55G     0.9521     0.6947      1.194         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.2it/s 8:33\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.8it/s 1:23\n",
      "                   all       7431      16299      0.848      0.773      0.859      0.655\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/15      3.57G     0.9458     0.6726      1.188         35        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.2it/s 8:32\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.8it/s 1:23\n",
      "                   all       7431      16299      0.854      0.774      0.861      0.658\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/15      3.58G     0.9333      0.659      1.178         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.2it/s 8:32\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.8it/s 1:22\n",
      "                   all       7431      16299      0.857      0.773      0.864      0.662\n",
      "\n",
      "15 epochs completed in 2.475 hours.\n",
      "Optimizer stripped from /kaggle/working/yolov8_training/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from /kaggle/working/yolov8_training/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating /kaggle/working/yolov8_training/weights/best.pt...\n",
      "Ultralytics 8.4.10 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 14913MiB)\n",
      "Model summary (fused): 73 layers, 3,006,623 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.7it/s 1:25\n",
      "                   all       7431      16299      0.857      0.773      0.864      0.663\n",
      "                   bus       1967       3248      0.863      0.751      0.858      0.599\n",
      "                   car       3695       8177      0.862      0.748      0.851      0.565\n",
      "                pickup       2048       2383      0.868      0.801      0.875      0.661\n",
      "                 truck       1586       2017      0.881      0.781      0.884      0.712\n",
      "                   van        455        474      0.812      0.785       0.85      0.776\n",
      "Speed: 0.1ms preprocess, 1.7ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Results saved to \u001b[1m/kaggle/working/yolov8_training\u001b[0m\n",
      "Model training completed.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# Clear GPU memory\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Load a pre-trained YOLOv8n model\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "\n",
    "# Optimized training configuration for Kaggle\n",
    "print(\"Initiating model training...\")\n",
    "results = model.train(\n",
    "    data=str(yolo_yaml_path),\n",
    "    epochs=15,\n",
    "    imgsz=640,\n",
    "    batch=16,  # Adjust based on GPU memory (try 8 or 32)\n",
    "    device=0,  # Use GPU\n",
    "    cache='disk',  # Use disk caching instead of RAM (Kaggle has limited RAM)\n",
    "    workers=2,  # Reduce workers to save RAM\n",
    "    patience=5,  # Early stopping\n",
    "    save=True,\n",
    "    save_period=5,  # Save checkpoint every 5 epochs\n",
    "    project='/kaggle/working',  # Save to Kaggle working directory\n",
    "    name='yolov8_training',\n",
    "    exist_ok=True,\n",
    "    pretrained=True,\n",
    "    optimizer='AdamW',  # Often works better than SGD\n",
    "    verbose=True,\n",
    "    seed=42,\n",
    "    deterministic=False,  # Faster training\n",
    "    single_cls=False,\n",
    "    rect=False,\n",
    "    cos_lr=True,  # Cosine learning rate scheduler\n",
    "    close_mosaic=10,  # Disable mosaic augmentation in last 10 epochs\n",
    "    amp=True,  # Automatic Mixed Precision for faster training\n",
    "    fraction=1.0,  # Use full dataset\n",
    "    profile=False,  # Disable profiling to save memory\n",
    "    # Augmentation parameters\n",
    "    hsv_h=0.015,\n",
    "    hsv_s=0.7,\n",
    "    hsv_v=0.4,\n",
    "    degrees=0.0,\n",
    "    translate=0.1,\n",
    "    scale=0.5,\n",
    "    shear=0.0,\n",
    "    perspective=0.0,\n",
    "    flipud=0.0,\n",
    "    fliplr=0.5,\n",
    "    mosaic=1.0,\n",
    "    mixup=0.0,\n",
    ")\n",
    "\n",
    "print(\"Model training completed.\")\n",
    "\n",
    "# Clear memory after training\n",
    "del model\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Load the best model for inference\n",
    "best_model = YOLO('/kaggle/working/yolov8_training/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26a8cb26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T13:31:25.068226Z",
     "iopub.status.busy": "2026-02-03T13:31:25.067492Z",
     "iopub.status.idle": "2026-02-03T13:33:08.304852Z",
     "shell.execute_reply": "2026-02-03T13:33:08.303888Z"
    },
    "papermill": {
     "duration": 104.581697,
     "end_time": "2026-02-03T13:33:08.306642",
     "exception": false,
     "start_time": "2026-02-03T13:31:23.724945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Loading model: /kaggle/working/yolov8_training/weights/best.pt\n",
      "\n",
      "ğŸ” Validating YOLOv8 model...\n",
      "Ultralytics 8.4.10 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 14913MiB)\n",
      "Model summary (fused): 73 layers, 3,006,623 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 178.4Â±158.8 MB/s, size: 90.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/val/labels... 7431 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 7431/7431 785.7it/s 9.5s\n",
      "WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/val is not writable, cache not saved.\n",
      "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 37, len(boxes) = 16299. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 465/465 5.2it/s 1:29\n",
      "                   all       7431      16299      0.859      0.773      0.864      0.662\n",
      "                   bus       1967       3248      0.864       0.75      0.858      0.599\n",
      "                   car       3695       8177      0.863      0.748      0.851      0.565\n",
      "                pickup       2048       2383      0.867      0.802      0.875      0.661\n",
      "                 truck       1586       2017      0.881      0.781      0.884      0.711\n",
      "                   van        455        474      0.817      0.787       0.85      0.775\n",
      "Speed: 0.8ms preprocess, 2.9ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Results saved to \u001b[1m/kaggle/working/runs/detect/val\u001b[0m\n",
      "\n",
      "ğŸ“Š Validation Results:\n",
      "   mAP50:     0.8639\n",
      "   mAP50-95:  0.6624\n",
      "   Precision: 0.8585\n",
      "   Recall:    0.7735\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "WORKING_DIR = Path(\"/kaggle/working\")\n",
    "best_model_path = WORKING_DIR / \"yolov8_training/weights/best.pt\"\n",
    "\n",
    "# Load the trained model\n",
    "print(f\"ğŸ“‚ Loading model: {best_model_path}\")\n",
    "model = YOLO(str(best_model_path))\n",
    "\n",
    "# Validate\n",
    "print(\"\\nğŸ” Validating YOLOv8 model...\")\n",
    "metrics = model.val()\n",
    "\n",
    "# Display all metrics\n",
    "print(f\"\\nğŸ“Š Validation Results:\")\n",
    "print(f\"   mAP50:     {metrics.box.map50:.4f}\")\n",
    "print(f\"   mAP50-95:  {metrics.box.map:.4f}\")\n",
    "print(f\"   Precision: {metrics.box.mp:.4f}\")\n",
    "print(f\"   Recall:    {metrics.box.mr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7cbf093",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T13:33:10.923889Z",
     "iopub.status.busy": "2026-02-03T13:33:10.923490Z",
     "iopub.status.idle": "2026-02-03T13:33:10.939283Z",
     "shell.execute_reply": "2026-02-03T13:33:10.938340Z"
    },
    "papermill": {
     "duration": 1.274064,
     "end_time": "2026-02-03T13:33:10.940869",
     "exception": false,
     "start_time": "2026-02-03T13:33:09.666805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… data_yolo.yaml file saved to: /kaggle/working/data_yolo.yaml\n",
      "\n",
      "Content of data_yolo.yaml:\n",
      "path: /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles\n",
      "train: train/images\n",
      "val: val/images\n",
      "test: test/images\n",
      "nc: 5\n",
      "names:\n",
      "- bus\n",
      "- car\n",
      "- pickup\n",
      "- truck\n",
      "- van\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "# Dataset root (read-only)\n",
    "DATASET_DIR = Path(\"/kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles\")\n",
    "\n",
    "# Writable directory\n",
    "WORKING_DIR = Path(\"/kaggle/working\")\n",
    "\n",
    "# ---- Read existing data.yaml ----\n",
    "original_yaml = DATASET_DIR / \"data.yaml\"\n",
    "\n",
    "if not original_yaml.exists():\n",
    "    raise FileNotFoundError(\"âŒ data.yaml not found in dataset directory\")\n",
    "\n",
    "with open(original_yaml, \"r\") as f:\n",
    "    original_data = yaml.safe_load(f)\n",
    "\n",
    "# Extract class info\n",
    "classes = original_data.get(\"names\", [])\n",
    "nc = original_data.get(\"nc\", len(classes))\n",
    "\n",
    "if not classes or nc == 0:\n",
    "    raise ValueError(\"âŒ No classes found in original data.yaml\")\n",
    "\n",
    "# ---- Create new YOLO config ----\n",
    "yolo_data_config = {\n",
    "    \"path\": str(DATASET_DIR.resolve()),\n",
    "    \"train\": \"train/images\",\n",
    "    \"val\": \"val/images\",\n",
    "    \"test\": \"test/images\",\n",
    "    \"nc\": nc,\n",
    "    \"names\": classes\n",
    "}\n",
    "\n",
    "# Save new YAML\n",
    "yolo_yaml_path = WORKING_DIR / \"data_yolo.yaml\"\n",
    "with open(yolo_yaml_path, \"w\") as f:\n",
    "    yaml.dump(yolo_data_config, f, sort_keys=False)\n",
    "\n",
    "# Print confirmation\n",
    "print(f\"âœ… data_yolo.yaml file saved to: {yolo_yaml_path}\\n\")\n",
    "print(\"Content of data_yolo.yaml:\")\n",
    "print(yolo_yaml_path.read_text())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4aa4e52f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T13:33:13.639695Z",
     "iopub.status.busy": "2026-02-03T13:33:13.639319Z",
     "iopub.status.idle": "2026-02-03T16:13:25.345603Z",
     "shell.execute_reply": "2026-02-03T16:13:25.344734Z"
    },
    "papermill": {
     "duration": 9615.132665,
     "end_time": "2026-02-03T16:13:27.419426",
     "exception": false,
     "start_time": "2026-02-03T13:33:12.286761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolov10n.pt to 'yolov10n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.6MB 52.9MB/s 0.1s\n",
      "Initiating model training...\n",
      "New https://pypi.org/project/ultralytics/8.4.11 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.4.10 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 14913MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=disk, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/kaggle/working/data_yolo.yaml, degrees=0.0, deterministic=False, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=15, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10n.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=yolov10_training, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=5, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/yolov10_training, save_frames=False, save_json=False, save_period=5, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1      9856  ultralytics.nn.modules.block.SCDown          [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.PSA             [256, 256]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 20                  -1  1     18048  ultralytics.nn.modules.block.SCDown          [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    282624  ultralytics.nn.modules.block.C2fCIB          [384, 256, 1, True, True]     \n",
      " 23        [16, 19, 22]  1    863278  ultralytics.nn.modules.head.v10Detect        [5, [64, 128, 256]]           \n",
      "YOLOv10n summary: 224 layers, 2,708,990 parameters, 2,708,974 gradients, 8.4 GFLOPs\n",
      "\n",
      "Transferred 493/595 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 198.9Â±178.4 MB/s, size: 181.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/train/labels... 26008 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 26008/26008 732.0it/s 35.5s\n",
      "WARNING âš ï¸ \u001b[34m\u001b[1mtrain: \u001b[0mCache directory /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/train is not writable, cache not saved.\n",
      "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 205, len(boxes) = 56400. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "WARNING âš ï¸ \u001b[34m\u001b[1mtrain: \u001b[0mSkipping caching images to disk, directory not writable\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 262.2Â±219.1 MB/s, size: 430.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/val/labels... 7431 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 7431/7431 904.9it/s 8.2s\n",
      "WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/val is not writable, cache not saved.\n",
      "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 37, len(boxes) = 16299. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mSkipping caching images to disk, directory not writable\n",
      "Plotting labels to /kaggle/working/yolov10_training/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.01, momentum=0.937) with parameter groups 95 weight(decay=0.0), 108 weight(decay=0.0005), 107 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m/kaggle/working/yolov10_training\u001b[0m\n",
      "Starting training for 15 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/15      2.84G      1.464       2.14      1.462         45        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 2.9it/s 9:19\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 1.6it/s 2:26\n",
      "                   all       7431      16299      0.288      0.296      0.237      0.124\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/15      4.14G      1.436      1.799       1.44         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.0it/s 9:00\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.6it/s 1:29\n",
      "                   all       7431      16299      0.495      0.459       0.47      0.315\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/15      4.15G      1.359      1.611      1.381         35        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.0it/s 9:04\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.7it/s 1:27\n",
      "                   all       7431      16299      0.459      0.387      0.376      0.225\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/15      4.18G      1.302      1.458      1.344         30        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.0it/s 9:01\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 3.0it/s 1:18\n",
      "                   all       7431      16299      0.694      0.599      0.681      0.482\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/15      4.19G      1.258      1.347      1.317         27        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.0it/s 8:57\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.6it/s 1:29\n",
      "                   all       7431      16299      0.719      0.632      0.716       0.51\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/15      4.21G      1.237      1.197      1.343         22        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.0it/s 8:58\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.7it/s 1:27\n",
      "                   all       7431      16299      0.754      0.645      0.732      0.532\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/15      4.22G      1.194      1.108      1.309         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.0it/s 8:57\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 3.0it/s 1:19\n",
      "                   all       7431      16299      0.756      0.677      0.766       0.56\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/15      4.24G      1.169      1.036      1.284          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.1it/s 8:49\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.5it/s 1:33\n",
      "                   all       7431      16299      0.771      0.688      0.779      0.578\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/15      4.25G      1.144     0.9743      1.266         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.0it/s 8:59\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.6it/s 1:28\n",
      "                   all       7431      16299      0.808      0.712      0.808      0.603\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/15      4.27G       1.12     0.9205      1.238         25        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.1it/s 8:51\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.7it/s 1:28\n",
      "                   all       7431      16299      0.833      0.721      0.822       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/15      4.28G      1.095       0.87      1.226         34        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.0it/s 8:55\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 3.0it/s 1:17\n",
      "                   all       7431      16299      0.827      0.745      0.834      0.632\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/15       4.3G      1.077     0.8413      1.212         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.1it/s 8:53\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.6it/s 1:30\n",
      "                   all       7431      16299      0.828      0.752      0.841      0.641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/15      4.31G      1.063     0.8131      1.203         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.1it/s 8:52\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.6it/s 1:30\n",
      "                   all       7431      16299      0.836      0.755      0.846      0.646\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/15      4.33G      1.055     0.7937      1.197         35        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.0it/s 9:02\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 3.0it/s 1:19\n",
      "                   all       7431      16299      0.844      0.759       0.85      0.649\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/15      4.34G      1.044      0.784       1.19         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.0it/s 9:01\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.9it/s 1:21\n",
      "                   all       7431      16299      0.834      0.763      0.851      0.651\n",
      "\n",
      "15 epochs completed in 2.621 hours.\n",
      "Optimizer stripped from /kaggle/working/yolov10_training/weights/last.pt, 5.7MB\n",
      "Optimizer stripped from /kaggle/working/yolov10_training/weights/best.pt, 5.7MB\n",
      "\n",
      "Validating /kaggle/working/yolov10_training/weights/best.pt...\n",
      "Ultralytics 8.4.10 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 14913MiB)\n",
      "YOLOv10n summary (fused): 102 layers, 2,266,143 parameters, 0 gradients, 6.5 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.7it/s 1:25\n",
      "                   all       7431      16299      0.836      0.762      0.851      0.651\n",
      "                   bus       1967       3248      0.838      0.751      0.845      0.588\n",
      "                   car       3695       8177      0.839      0.726      0.834       0.55\n",
      "                pickup       2048       2383      0.844      0.783      0.866      0.659\n",
      "                 truck       1586       2017      0.872      0.767      0.862      0.692\n",
      "                   van        455        474      0.785      0.784      0.846      0.765\n",
      "Speed: 0.2ms preprocess, 1.8ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
      "Results saved to \u001b[1m/kaggle/working/yolov10_training\u001b[0m\n",
      "Model training completed.\n",
      "Best model loaded from: /kaggle/working/yolov10_training/weights/best.pt\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# Clear GPU memory\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Load a pre-trained YOLOv10n model\n",
    "model = YOLO('yolov10n.pt')\n",
    "\n",
    "# Optimized training configuration for Kaggle\n",
    "print(\"Initiating model training...\")\n",
    "results = model.train(\n",
    "    data=str(yolo_yaml_path),\n",
    "    epochs=15,\n",
    "    imgsz=640,\n",
    "    batch=16,  # Adjust: 8 (safer), 16 (balanced), 32 (if no OOM)\n",
    "    device=0,  # GPU\n",
    "    cache='disk',  # Critical for Kaggle: disk cache instead of RAM\n",
    "    workers=2,  # Reduce RAM usage\n",
    "    patience=5,  # Early stopping\n",
    "    save=True,\n",
    "    save_period=5,  # Save checkpoint every 5 epochs\n",
    "    project='/kaggle/working',  # Kaggle persistent directory\n",
    "    name='yolov10_training',\n",
    "    exist_ok=True,\n",
    "    pretrained=True,\n",
    "    optimizer='AdamW',\n",
    "    verbose=True,\n",
    "    seed=42,\n",
    "    deterministic=False,\n",
    "    amp=True,  # Automatic Mixed Precision - faster training\n",
    "    cos_lr=True,  # Cosine LR scheduler\n",
    "    close_mosaic=10,  # Disable mosaic in last 10 epochs\n",
    "    profile=False,  # Save memory\n",
    "    # Augmentation parameters (augment=True is deprecated, use individual params)\n",
    "    hsv_h=0.015,\n",
    "    hsv_s=0.7,\n",
    "    hsv_v=0.4,\n",
    "    degrees=0.0,\n",
    "    translate=0.1,\n",
    "    scale=0.5,\n",
    "    shear=0.0,\n",
    "    perspective=0.0,\n",
    "    flipud=0.0,\n",
    "    fliplr=0.5,\n",
    "    mosaic=1.0,\n",
    "    mixup=0.0,\n",
    "    copy_paste=0.0,\n",
    ")\n",
    "\n",
    "print(\"Model training completed.\")\n",
    "\n",
    "# Clear memory\n",
    "del model\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Load best model\n",
    "best_model = YOLO('/kaggle/working/yolov10_training/weights/best.pt')\n",
    "print(f\"Best model loaded from: /kaggle/working/yolov10_training/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1d1d065",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T16:13:32.416200Z",
     "iopub.status.busy": "2026-02-03T16:13:32.415530Z",
     "iopub.status.idle": "2026-02-03T16:15:12.489207Z",
     "shell.execute_reply": "2026-02-03T16:15:12.488321Z"
    },
    "papermill": {
     "duration": 102.593591,
     "end_time": "2026-02-03T16:15:12.490719",
     "exception": false,
     "start_time": "2026-02-03T16:13:29.897128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Loading model: /kaggle/working/yolov10_training/weights/best.pt\n",
      "\n",
      "ğŸ” Validating YOLOv10n model...\n",
      "Ultralytics 8.4.10 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 14913MiB)\n",
      "YOLOv10n summary (fused): 102 layers, 2,266,143 parameters, 0 gradients, 6.5 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 513.3Â±629.8 MB/s, size: 334.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/val/labels... 7431 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 7431/7431 803.1it/s 9.3s\n",
      "WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/val is not writable, cache not saved.\n",
      "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 37, len(boxes) = 16299. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 465/465 5.4it/s 1:26\n",
      "                   all       7431      16299      0.836      0.762       0.85       0.65\n",
      "                   bus       1967       3248      0.839       0.75      0.845      0.587\n",
      "                   car       3695       8177       0.84      0.726      0.834       0.55\n",
      "                pickup       2048       2383      0.844      0.782      0.865      0.658\n",
      "                 truck       1586       2017      0.871      0.768      0.862      0.692\n",
      "                   van        455        474      0.788      0.783      0.846      0.765\n",
      "Speed: 0.7ms preprocess, 2.9ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
      "Results saved to \u001b[1m/kaggle/working/runs/detect/val2\u001b[0m\n",
      "\n",
      "ğŸ“Š Validation Results:\n",
      "   mAP50:     0.8503\n",
      "   mAP50-95:  0.6505\n",
      "   Precision: 0.8365\n",
      "   Recall:    0.7617\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "WORKING_DIR = Path(\"/kaggle/working\")\n",
    "best_model_path = WORKING_DIR / \"yolov10_training/weights/best.pt\"\n",
    "\n",
    "# Load the trained model\n",
    "print(f\"ğŸ“‚ Loading model: {best_model_path}\")\n",
    "model = YOLO(str(best_model_path))\n",
    "\n",
    "# Validate\n",
    "print(\"\\nğŸ” Validating YOLOv10n model...\")\n",
    "metrics = model.val()\n",
    "\n",
    "# Display all metrics\n",
    "print(f\"\\nğŸ“Š Validation Results:\")\n",
    "print(f\"   mAP50:     {metrics.box.map50:.4f}\")\n",
    "print(f\"   mAP50-95:  {metrics.box.map:.4f}\")\n",
    "print(f\"   Precision: {metrics.box.mp:.4f}\")\n",
    "print(f\"   Recall:    {metrics.box.mr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5db65b5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T16:15:17.557955Z",
     "iopub.status.busy": "2026-02-03T16:15:17.557300Z",
     "iopub.status.idle": "2026-02-03T16:15:17.571075Z",
     "shell.execute_reply": "2026-02-03T16:15:17.570256Z"
    },
    "papermill": {
     "duration": 2.549257,
     "end_time": "2026-02-03T16:15:17.572658",
     "exception": false,
     "start_time": "2026-02-03T16:15:15.023401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… data_yolo.yaml file saved to: /kaggle/working/data_yolo.yaml\n",
      "\n",
      "Content of data_yolo.yaml:\n",
      "path: /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles\n",
      "train: train/images\n",
      "val: val/images\n",
      "test: test/images\n",
      "nc: 5\n",
      "names:\n",
      "- bus\n",
      "- car\n",
      "- pickup\n",
      "- truck\n",
      "- van\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "# Dataset root (read-only)\n",
    "DATASET_DIR = Path(\"/kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles\")\n",
    "# Writable directory\n",
    "WORKING_DIR = Path(\"/kaggle/working\")\n",
    "\n",
    "# ---- Read existing data.yaml ----\n",
    "original_yaml = DATASET_DIR / \"data.yaml\"\n",
    "if not original_yaml.exists():\n",
    "    raise FileNotFoundError(\"âŒ data.yaml not found in dataset directory\")\n",
    "\n",
    "with open(original_yaml, \"r\") as f:\n",
    "    original_data = yaml.safe_load(f)\n",
    "\n",
    "# Extract class info\n",
    "classes = original_data.get(\"names\", [])\n",
    "nc = original_data.get(\"nc\", len(classes))\n",
    "\n",
    "if not classes or nc == 0:\n",
    "    raise ValueError(\"âŒ No classes found in original data.yaml\")\n",
    "\n",
    "# ---- Create new YOLO config ----\n",
    "yolo_data_config = {\n",
    "    \"path\": str(DATASET_DIR.resolve()),\n",
    "    \"train\": \"train/images\",\n",
    "    \"val\": \"val/images\",\n",
    "    \"test\": \"test/images\",\n",
    "    \"nc\": nc,\n",
    "    \"names\": classes\n",
    "}\n",
    "\n",
    "# Save new YAML\n",
    "yolo_yaml_path = WORKING_DIR / \"data_yolo.yaml\"\n",
    "with open(yolo_yaml_path, \"w\") as f:\n",
    "    yaml.dump(yolo_data_config, f, sort_keys=False)\n",
    "\n",
    "# Print confirmation\n",
    "print(f\"âœ… data_yolo.yaml file saved to: {yolo_yaml_path}\\n\")\n",
    "print(\"Content of data_yolo.yaml:\")\n",
    "print(yolo_yaml_path.read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6635525e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T16:15:22.775667Z",
     "iopub.status.busy": "2026-02-03T16:15:22.774922Z",
     "iopub.status.idle": "2026-02-03T19:41:24.133492Z",
     "shell.execute_reply": "2026-02-03T19:41:24.132516Z"
    },
    "papermill": {
     "duration": 12363.932517,
     "end_time": "2026-02-03T19:41:24.135352",
     "exception": false,
     "start_time": "2026-02-03T16:15:20.202835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 30.4MB/s 0.2s\n",
      "ğŸš€ Initiating YOLOv11 model training...\n",
      "New https://pypi.org/project/ultralytics/8.4.11 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.4.10 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 14913MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=disk, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/kaggle/working/data_yolo.yaml, degrees=0.0, deterministic=False, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=vehicle_detection, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=5, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/yolov11_training, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/yolov11_training/vehicle_detection, save_frames=False, save_json=False, save_period=5, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    431647  ultralytics.nn.modules.head.Detect           [5, 16, None, [64, 128, 256]] \n",
      "YOLO11n summary: 182 layers, 2,590,815 parameters, 2,590,799 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 289.9Â±340.9 MB/s, size: 181.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/train/labels... 26008 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 26008/26008 775.8it/s 33.5s\n",
      "WARNING âš ï¸ \u001b[34m\u001b[1mtrain: \u001b[0mCache directory /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/train is not writable, cache not saved.\n",
      "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 205, len(boxes) = 56400. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "WARNING âš ï¸ \u001b[34m\u001b[1mtrain: \u001b[0mSkipping caching images to disk, directory not writable\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 373.2Â±474.3 MB/s, size: 430.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/val/labels... 7431 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 7431/7431 964.2it/s 7.7s\n",
      "WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/val is not writable, cache not saved.\n",
      "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 37, len(boxes) = 16299. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mSkipping caching images to disk, directory not writable\n",
      "Plotting labels to /kaggle/working/yolov11_training/vehicle_detection/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.01, momentum=0.937) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m/kaggle/working/yolov11_training/vehicle_detection\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/20      2.35G      1.319      1.767      1.468         45        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.1it/s 8:48\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 3.0it/s 1:18\n",
      "                   all       7431      16299      0.308      0.442      0.286       0.15\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/20      3.55G       1.26      1.529      1.422         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.1it/s 8:47\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.7it/s 1:25\n",
      "                   all       7431      16299      0.431      0.475      0.442       0.26\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/20      3.56G      1.197      1.387      1.376         35        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.0it/s 8:58\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.5it/s 1:33\n",
      "                   all       7431      16299       0.59      0.556      0.555      0.366\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/20      3.58G      1.154      1.265      1.341         30        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.0it/s 8:55\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.5it/s 1:34\n",
      "                   all       7431      16299      0.675      0.614      0.683      0.467\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/20      3.59G      1.111      1.181       1.31         27        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.2it/s 8:27\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.9it/s 1:22\n",
      "                   all       7431      16299      0.697      0.653      0.712      0.503\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/20      3.61G      1.081      1.117      1.289         33        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.2it/s 8:31\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.4it/s 1:36\n",
      "                   all       7431      16299      0.754      0.671      0.742      0.526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/20      3.62G      1.064      1.067      1.273         55        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.1it/s 8:46\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.9it/s 1:19\n",
      "                   all       7431      16299      0.774      0.694      0.779      0.567\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/20      3.64G      1.044      1.024      1.259         41        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.1it/s 8:41\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.8it/s 1:23\n",
      "                   all       7431      16299      0.789      0.715      0.793      0.577\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/20      3.65G      1.027     0.9846      1.245         37        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.2it/s 8:33\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.5it/s 1:32\n",
      "                   all       7431      16299        0.8      0.716      0.807      0.596\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/20      3.67G      1.006     0.9507      1.232         39        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.3it/s 8:14\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.5it/s 1:33\n",
      "                   all       7431      16299      0.804      0.739      0.821       0.61\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/20      3.68G      1.033     0.8491      1.254         34        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.2it/s 8:21\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 3.0it/s 1:18\n",
      "                   all       7431      16299      0.824      0.748      0.831       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/20      3.71G      1.012     0.8062      1.238         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.1it/s 8:41\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.8it/s 1:24\n",
      "                   all       7431      16299      0.844      0.753      0.844      0.636\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/20      3.71G     0.9933     0.7683       1.22         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.1it/s 8:48\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 3.0it/s 1:19\n",
      "                   all       7431      16299      0.835      0.765      0.851      0.643\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/20      3.73G     0.9785     0.7377      1.208         35        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.1it/s 8:47\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.6it/s 1:29\n",
      "                   all       7431      16299      0.853      0.761      0.854      0.649\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/20      3.74G      0.963     0.7118      1.192         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.2it/s 8:29\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.6it/s 1:31\n",
      "                   all       7431      16299      0.845      0.778       0.86      0.655\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/20      3.76G     0.9498     0.6875      1.183         18        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.3it/s 8:07\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.7it/s 1:26\n",
      "                   all       7431      16299      0.846      0.785      0.864      0.661\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/20      3.77G     0.9401     0.6707      1.176         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.1it/s 8:53\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.4it/s 1:37\n",
      "                   all       7431      16299      0.852      0.781      0.868      0.665\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/20      3.79G     0.9335     0.6541      1.168         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.2it/s 8:32\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.9it/s 1:20\n",
      "                   all       7431      16299      0.852      0.781      0.869      0.667\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/20       3.8G     0.9244     0.6423      1.164         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.2it/s 8:33\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.7it/s 1:27\n",
      "                   all       7431      16299      0.862      0.779      0.869      0.667\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/20      3.82G     0.9207     0.6399      1.163         24        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1626/1626 3.2it/s 8:28\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.5it/s 1:31\n",
      "                   all       7431      16299      0.861      0.779       0.87      0.668\n",
      "\n",
      "20 epochs completed in 3.359 hours.\n",
      "Optimizer stripped from /kaggle/working/yolov11_training/vehicle_detection/weights/last.pt, 5.4MB\n",
      "Optimizer stripped from /kaggle/working/yolov11_training/vehicle_detection/weights/best.pt, 5.4MB\n",
      "\n",
      "Validating /kaggle/working/yolov11_training/vehicle_detection/weights/best.pt...\n",
      "Ultralytics 8.4.10 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 14913MiB)\n",
      "YOLO11n summary (fused): 101 layers, 2,583,127 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 233/233 2.6it/s 1:29\n",
      "                   all       7431      16299      0.864      0.776       0.87      0.668\n",
      "                   bus       1967       3248      0.871      0.753      0.865      0.604\n",
      "                   car       3695       8177      0.861      0.741      0.853      0.565\n",
      "                pickup       2048       2383      0.865      0.812      0.886      0.674\n",
      "                 truck       1586       2017      0.903      0.768      0.879      0.711\n",
      "                   van        455        474       0.82      0.808      0.865      0.785\n",
      "Speed: 0.1ms preprocess, 1.8ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Results saved to \u001b[1m/kaggle/working/yolov11_training/vehicle_detection\u001b[0m\n",
      "âœ… YOLOv11 model training completed.\n",
      "ğŸ“¦ Loading best trained model...\n",
      "âœ… Best model loaded from: /kaggle/working/yolov11_training/vehicle_detection/weights/best.pt\n",
      "ğŸ“Š Validating model performance...\n",
      "Ultralytics 8.4.10 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 14913MiB)\n",
      "YOLO11n summary (fused): 101 layers, 2,583,127 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 441.3Â±606.5 MB/s, size: 334.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/val/labels... 7431 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 7431/7431 750.4it/s 9.9s\n",
      "WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/val is not writable, cache not saved.\n",
      "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 37, len(boxes) = 16299. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 465/465 5.3it/s 1:28\n",
      "                   all       7431      16299       0.86      0.781       0.87      0.668\n",
      "                   bus       1967       3248      0.864      0.756      0.865      0.604\n",
      "                   car       3695       8177      0.857      0.748      0.853      0.566\n",
      "                pickup       2048       2383      0.861      0.816      0.886      0.673\n",
      "                 truck       1586       2017      0.898       0.77      0.879      0.711\n",
      "                   van        455        474      0.821      0.814      0.864      0.785\n",
      "Speed: 0.8ms preprocess, 2.8ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Results saved to \u001b[1m/kaggle/working/runs/detect/val3\u001b[0m\n",
      "mAP50-95: 0.667889678946715\n",
      "mAP50: 0.8697046329787067\n",
      "mAP75: 0.729831382121437\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# Clear GPU memory\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Load a pre-trained YOLOv11n model\n",
    "model = YOLO('yolo11n.pt')\n",
    "\n",
    "# Train the model\n",
    "print(\"ğŸš€ Initiating YOLOv11 model training...\")\n",
    "results = model.train(\n",
    "    data=str(yolo_yaml_path), \n",
    "    epochs=20, \n",
    "    imgsz=640, \n",
    "    batch=16,  # Adjust: 8 (safer), 16 (balanced), 24-32 (if no OOM)\n",
    "    device=0,  # Enable GPU - CRITICAL for Kaggle!\n",
    "    cache='disk',  # Use disk cache instead of RAM (Kaggle has limited RAM)\n",
    "    workers=2,  # Reduce RAM usage from data loading\n",
    "    patience=5,  # Early stopping to save GPU hours\n",
    "    save=True,\n",
    "    save_period=5,  # Save checkpoint every 5 epochs (safety for timeouts)\n",
    "    project='/kaggle/working/yolov11_training',  # Kaggle persistent directory\n",
    "    name='vehicle_detection',\n",
    "    exist_ok=True,\n",
    "    pretrained=True,\n",
    "    optimizer='AdamW',  # Often better than SGD\n",
    "    verbose=True,\n",
    "    seed=42,\n",
    "    deterministic=False,  # Faster training\n",
    "    amp=True,  # Automatic Mixed Precision - faster on T4/P100\n",
    "    cos_lr=True,  # Cosine learning rate scheduler\n",
    "    close_mosaic=10,  # Disable mosaic in last 10 epochs for better accuracy\n",
    "    profile=False,  # Disable profiling to save memory\n",
    "    plots=True,  # Generate training plots\n",
    "    # Augmentation parameters (augment=True is deprecated)\n",
    "    hsv_h=0.015,  # Hue augmentation\n",
    "    hsv_s=0.7,    # Saturation augmentation\n",
    "    hsv_v=0.4,    # Value augmentation\n",
    "    degrees=0.0,  # Rotation (0-10 for vehicles)\n",
    "    translate=0.1,  # Translation\n",
    "    scale=0.5,    # Scale augmentation\n",
    "    shear=0.0,    # Shear\n",
    "    perspective=0.0,  # Perspective\n",
    "    flipud=0.0,   # Vertical flip (usually 0 for vehicles)\n",
    "    fliplr=0.5,   # Horizontal flip (0.5 for vehicles)\n",
    "    mosaic=1.0,   # Mosaic augmentation\n",
    "    mixup=0.0,    # Mixup augmentation\n",
    "    copy_paste=0.0,  # Copy-paste augmentation\n",
    ")\n",
    "print(\"âœ… YOLOv11 model training completed.\")\n",
    "\n",
    "# Clear memory after training\n",
    "del model\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Load the best model for validation/inference\n",
    "print(\"ğŸ“¦ Loading best trained model...\")\n",
    "best_model = YOLO('/kaggle/working/yolov11_training/vehicle_detection/weights/best.pt')\n",
    "print(f\"âœ… Best model loaded from: /kaggle/working/yolov11_training/vehicle_detection/weights/best.pt\")\n",
    "\n",
    "# Optional: Validate the model\n",
    "print(\"ğŸ“Š Validating model performance...\")\n",
    "metrics = best_model.val()\n",
    "print(f\"mAP50-95: {metrics.box.map}\")\n",
    "print(f\"mAP50: {metrics.box.map50}\")\n",
    "print(f\"mAP75: {metrics.box.map75}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f6880c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T19:41:32.480528Z",
     "iopub.status.busy": "2026-02-03T19:41:32.479741Z",
     "iopub.status.idle": "2026-02-03T19:43:12.260501Z",
     "shell.execute_reply": "2026-02-03T19:43:12.259679Z"
    },
    "papermill": {
     "duration": 103.940232,
     "end_time": "2026-02-03T19:43:12.261971",
     "exception": false,
     "start_time": "2026-02-03T19:41:28.321739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Loading model: /kaggle/working/yolov11_training/vehicle_detection/weights/best.pt\n",
      "\n",
      "ğŸ” Validating YOLOv11 model...\n",
      "Ultralytics 8.4.10 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 14913MiB)\n",
      "YOLO11n summary (fused): 101 layers, 2,583,127 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 229.1Â±303.3 MB/s, size: 118.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/val/labels... 7431 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 7431/7431 950.6it/s 7.8s\n",
      "WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/vehicle-object-detection-dataset-5-classes/vehicles/val is not writable, cache not saved.\n",
      "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 37, len(boxes) = 16299. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 465/465 5.3it/s 1:27\n",
      "                   all       7431      16299       0.86      0.781       0.87      0.668\n",
      "                   bus       1967       3248      0.864      0.756      0.865      0.604\n",
      "                   car       3695       8177      0.857      0.748      0.853      0.566\n",
      "                pickup       2048       2383      0.861      0.816      0.886      0.673\n",
      "                 truck       1586       2017      0.898       0.77      0.879      0.711\n",
      "                   van        455        474      0.821      0.814      0.864      0.785\n",
      "Speed: 0.7ms preprocess, 2.7ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1m/kaggle/working/runs/detect/val4\u001b[0m\n",
      "\n",
      "ğŸ“Š Validation Results:\n",
      "   mAP50:     0.8697\n",
      "   mAP50-95:  0.6679\n",
      "   Precision: 0.8602\n",
      "   Recall:    0.7807\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "WORKING_DIR = Path(\"/kaggle/working\")\n",
    "best_model_path = WORKING_DIR / \"yolov11_training/vehicle_detection/weights/best.pt\"\n",
    "\n",
    "# Load the trained model\n",
    "print(f\"ğŸ“‚ Loading model: {best_model_path}\")\n",
    "model = YOLO(str(best_model_path))\n",
    "\n",
    "# Validate\n",
    "print(\"\\nğŸ” Validating YOLOv11 model...\")  # Fixed comment\n",
    "metrics = model.val()\n",
    "\n",
    "# Display all metrics\n",
    "print(f\"\\nğŸ“Š Validation Results:\")\n",
    "print(f\"   mAP50:     {metrics.box.map50:.4f}\")\n",
    "print(f\"   mAP50-95:  {metrics.box.map:.4f}\")\n",
    "print(f\"   Precision: {metrics.box.mp:.4f}\")\n",
    "print(f\"   Recall:    {metrics.box.mr:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 9238653,
     "isSourceIdPinned": false,
     "sourceId": 14464186,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 31589.694001,
   "end_time": "2026-02-03T19:43:20.650082",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-02-03T10:56:50.956081",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
